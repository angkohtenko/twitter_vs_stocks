{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "pythondata",
   "display_name": "Python 3.8.5 64-bit ('PythonData': conda)"
  },
  "interpreter": {
   "hash": "dd600c1e32c3b68d98e7c9239ab6282fbb57786a2604389a60edb55a27cdb977"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn as skl\n",
    "import ast\n",
    "\n",
    "from config import user, password, hostname"
   ]
  },
  {
   "source": [
    "# Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Connecting to database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['stock', 'tweets_text', 'twitter_vs_stocks']"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "# Create engine\n",
    "engine = create_engine(f'postgres://{user}:{password}@{hostname}/twitter_vs_stocks')\n",
    "\n",
    "# Use the Inspector to explore the database and print the table names\n",
    "inspector = inspect(engine)\n",
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               tokenized_text  like_count  \\\n",
       "date                                                                        \n",
       "2021-07-09  ['solar', 'powerwall', 'battery', 'ensures', '...       37454   \n",
       "2021-07-09  ['tesla', 'solar', 'roof', 'powerwall', 'major...       13972   \n",
       "2021-07-09  ['autonomous', 'spacex', 'droneship', 'shortfa...       63291   \n",
       "2021-07-09  ['electrekco', 'bought', 'first', 'tesla', 'he...           0   \n",
       "2021-07-08                 ['maybe', 'movie', 'gaslit', 'us']       26485   \n",
       "\n",
       "            quote_count  reply_count  retweet_count    change  volume_traded  \n",
       "date                                                                          \n",
       "2021-07-09          400         4443           2871  4.140015       18118500  \n",
       "2021-07-09          119         2185           1407  4.140015       18118500  \n",
       "2021-07-09          860         3653           6553  4.140015       18118500  \n",
       "2021-07-09            0            0            979  4.140015       18118500  \n",
       "2021-07-08           92         1927           1045  8.159973       22773300  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokenized_text</th>\n      <th>like_count</th>\n      <th>quote_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n      <th>change</th>\n      <th>volume_traded</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-07-09</th>\n      <td>['solar', 'powerwall', 'battery', 'ensures', '...</td>\n      <td>37454</td>\n      <td>400</td>\n      <td>4443</td>\n      <td>2871</td>\n      <td>4.140015</td>\n      <td>18118500</td>\n    </tr>\n    <tr>\n      <th>2021-07-09</th>\n      <td>['tesla', 'solar', 'roof', 'powerwall', 'major...</td>\n      <td>13972</td>\n      <td>119</td>\n      <td>2185</td>\n      <td>1407</td>\n      <td>4.140015</td>\n      <td>18118500</td>\n    </tr>\n    <tr>\n      <th>2021-07-09</th>\n      <td>['autonomous', 'spacex', 'droneship', 'shortfa...</td>\n      <td>63291</td>\n      <td>860</td>\n      <td>3653</td>\n      <td>6553</td>\n      <td>4.140015</td>\n      <td>18118500</td>\n    </tr>\n    <tr>\n      <th>2021-07-09</th>\n      <td>['electrekco', 'bought', 'first', 'tesla', 'he...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>979</td>\n      <td>4.140015</td>\n      <td>18118500</td>\n    </tr>\n    <tr>\n      <th>2021-07-08</th>\n      <td>['maybe', 'movie', 'gaslit', 'us']</td>\n      <td>26485</td>\n      <td>92</td>\n      <td>1927</td>\n      <td>1045</td>\n      <td>8.159973</td>\n      <td>22773300</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "# Create dataframe from SQL table\n",
    "twitter_vs_stocks = pd.read_sql_table(\n",
    "    'twitter_vs_stocks',\n",
    "    con=engine)\n",
    "twitter_vs_stocks.set_index(['date'], inplace=True)\n",
    "twitter_vs_stocks.rename({'volume': 'volume_traded'}, axis=1, inplace=True)\n",
    "twitter_vs_stocks.head()"
   ]
  },
  {
   "source": [
    "### Defining the most common words in tweets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for counting words\n",
    "def count_words(str, n=None):\n",
    "    vect = CountVectorizer().fit(str)\n",
    "    bag_of_words = vect.transform(str)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "    freq = sorted(freq, key = lambda x: x[1], reverse=True)\n",
    "    return freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('spacex', 117),\n",
       " ('tesla', 81),\n",
       " ('falcon', 43),\n",
       " ('launch', 40),\n",
       " ('first', 34),\n",
       " ('dragon', 27),\n",
       " ('model', 22),\n",
       " ('mission', 21),\n",
       " ('starship', 20),\n",
       " ('crew', 20),\n",
       " ('flight', 18),\n",
       " ('landing', 17),\n",
       " ('space_station', 17),\n",
       " ('starlink', 16),\n",
       " ('doo', 15),\n",
       " ('stage', 15),\n",
       " ('next', 14),\n",
       " ('giga', 14),\n",
       " ('nasa', 14),\n",
       " ('doge', 13)]"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "# count words in tweets\n",
    "words_in_tweets = count_words(twitter_vs_stocks.tokenized_text)\n",
    "words_in_tweets[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "# analyse only words that appear 3 or more times\n",
    "words_to_analyse = [word for word, freq in words_in_tweets if freq >= 3]\n",
    "len(words_to_analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['spacex',\n",
       " 'tesla',\n",
       " 'falcon',\n",
       " 'launch',\n",
       " 'first',\n",
       " 'dragon',\n",
       " 'model',\n",
       " 'mission',\n",
       " 'starship',\n",
       " 'crew']"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "words_to_analyse[:10]"
   ]
  },
  {
   "source": [
    "### Count words in tweets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text tows from string to list \n",
    "twitter_vs_stocks.tokenized_text = [ast.literal_eval(row) for row in twitter_vs_stocks.tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count words in the tokenized text (tweets)\n",
    "for column in words_to_analyse:\n",
    "    count_list = []\n",
    "    for row in np.arange(0,len(twitter_vs_stocks.tokenized_text)):\n",
    "         count_list.append(twitter_vs_stocks.tokenized_text[row].count(column))\n",
    "    twitter_vs_stocks[column] = count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               tokenized_text  like_count  \\\n",
       "date                                                                        \n",
       "2021-07-09  [solar, powerwall, battery, ensures, home, nev...       37454   \n",
       "2021-07-09  [tesla, solar, roof, powerwall, major, new, ho...       13972   \n",
       "2021-07-09  [autonomous, spacex, droneship, shortfall, gra...       63291   \n",
       "2021-07-09  [electrekco, bought, first, tesla, herewhat, h...           0   \n",
       "2021-07-08                         [maybe, movie, gaslit, us]       26485   \n",
       "\n",
       "            quote_count  reply_count  retweet_count    change  volume_traded  \\\n",
       "date                                                                           \n",
       "2021-07-09          400         4443           2871  4.140015       18118500   \n",
       "2021-07-09          119         2185           1407  4.140015       18118500   \n",
       "2021-07-09          860         3653           6553  4.140015       18118500   \n",
       "2021-07-09            0            0            979  4.140015       18118500   \n",
       "2021-07-08           92         1927           1045  8.159973       22773300   \n",
       "\n",
       "            spacex  tesla  falcon  ...  tonight  volume  music  cell  saocom  \\\n",
       "date                               ...                                         \n",
       "2021-07-09       0      0       0  ...        0       0      0     0       0   \n",
       "2021-07-09       0      1       0  ...        0       0      0     0       0   \n",
       "2021-07-09       1      0       0  ...        0       0      0     0       0   \n",
       "2021-07-09       0      1       0  ...        0       0      0     0       0   \n",
       "2021-07-08       0      0       0  ...        0       0      0     0       0   \n",
       "\n",
       "            government  astro_doug  astrobehnken  special  interests  \n",
       "date                                                                  \n",
       "2021-07-09           0           0             0        0          0  \n",
       "2021-07-09           0           0             0        0          0  \n",
       "2021-07-09           0           0             0        0          0  \n",
       "2021-07-09           0           0             0        0          0  \n",
       "2021-07-08           0           0             0        0          0  \n",
       "\n",
       "[5 rows x 337 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokenized_text</th>\n      <th>like_count</th>\n      <th>quote_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n      <th>change</th>\n      <th>volume_traded</th>\n      <th>spacex</th>\n      <th>tesla</th>\n      <th>falcon</th>\n      <th>...</th>\n      <th>tonight</th>\n      <th>volume</th>\n      <th>music</th>\n      <th>cell</th>\n      <th>saocom</th>\n      <th>government</th>\n      <th>astro_doug</th>\n      <th>astrobehnken</th>\n      <th>special</th>\n      <th>interests</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-07-09</th>\n      <td>[solar, powerwall, battery, ensures, home, nev...</td>\n      <td>37454</td>\n      <td>400</td>\n      <td>4443</td>\n      <td>2871</td>\n      <td>4.140015</td>\n      <td>18118500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-09</th>\n      <td>[tesla, solar, roof, powerwall, major, new, ho...</td>\n      <td>13972</td>\n      <td>119</td>\n      <td>2185</td>\n      <td>1407</td>\n      <td>4.140015</td>\n      <td>18118500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-09</th>\n      <td>[autonomous, spacex, droneship, shortfall, gra...</td>\n      <td>63291</td>\n      <td>860</td>\n      <td>3653</td>\n      <td>6553</td>\n      <td>4.140015</td>\n      <td>18118500</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-09</th>\n      <td>[electrekco, bought, first, tesla, herewhat, h...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>979</td>\n      <td>4.140015</td>\n      <td>18118500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2021-07-08</th>\n      <td>[maybe, movie, gaslit, us]</td>\n      <td>26485</td>\n      <td>92</td>\n      <td>1927</td>\n      <td>1045</td>\n      <td>8.159973</td>\n      <td>22773300</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 337 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "twitter_vs_stocks.head()"
   ]
  },
  {
   "source": [
    "### Scaling and Features Extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = twitter_vs_stocks.drop(columns=['tokenized_text', 'change', 'volume_traded'])\n",
    "y_change = twitter_vs_stocks.change\n",
    "y_volume = twitter_vs_stocks.volume"
   ]
  },
  {
   "source": [
    "#### Tagret is Change"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to training and testing\n",
    "X_train, X_test, y_change_train, y_change_test = train_test_split(X, y_change, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler instance\n",
    "scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.85407441, -0.49206023, -0.57366483, ..., -0.04816831,\n",
       "        -0.04816831, -0.06819943],\n",
       "       [ 0.47466098,  0.15989215, -0.08196724, ..., -0.04816831,\n",
       "        -0.04816831, -0.06819943],\n",
       "       [ 0.08585003, -0.3510401 , -0.09456689, ..., -0.04816831,\n",
       "        -0.04816831, -0.06819943],\n",
       "       ...,\n",
       "       [ 1.10598082,  0.46177445,  0.30807759, ..., -0.04816831,\n",
       "        -0.04816831, -0.06819943],\n",
       "       [-0.10359992, -0.37655128, -0.26201784, ..., -0.04816831,\n",
       "        -0.04816831, -0.06819943],\n",
       "       [-0.49784035, -0.30899389, -0.38863658, ..., -0.04816831,\n",
       "        -0.04816831, -0.06819943]])"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the number of components in X to 10 using PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.fit_transform(X_test_scaled)"
   ]
  },
  {
   "source": [
    "#### Tagret is Volume Traded"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to training and testing\n",
    "X_train, X_test, y_volume_train, y_volume_test = train_test_split(X, y_volume, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the number of components in X to 10 using PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.fit_transform(X_test_scaled)"
   ]
  },
  {
   "source": [
    "# ML Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}