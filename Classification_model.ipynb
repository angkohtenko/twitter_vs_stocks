{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f3a362",
   "metadata": {},
   "source": [
    "# Machine Learning Model - Second Segment Project Deliverable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f8b11",
   "metadata": {},
   "source": [
    "## Model Plan\n",
    "- Prepare the dataframe with columns: tweet_text, price_previous day, price_next day, price_diff\n",
    "- Preprocess the tweet text into features (countVectorier, tfidf)\n",
    "- Classification: LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a412b2b",
   "metadata": {},
   "source": [
    "### Query the dataframe with columns: tweet_text, price_previous day, price_next day, price_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af82539e-5e32-4859-b979-65da960922b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up libraries:\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect \n",
    "from config import user, password, hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af61d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{hostname}/twitter_vs_stocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ffe9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new table for model, preprocessing the data\n",
    "\n",
    "tweets_price = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "        SELECT \n",
    "            tweets.date AS tweet_date,\n",
    "            tweets.text AS tweet_text,\n",
    "            tweets.tokenized_text AS tweet_tokens,\n",
    "            COALESCE(stock_prev.close, stock_prev_prev.close, stock_prev_prev_prev.close) AS prev_day_close,\n",
    "            COALESCE(stock_next.close, stock_next_next.close, stock_next_next_next.close) AS next_day_close\n",
    "        FROM tweets_text tweets\n",
    "        LEFT JOIN stock stock_prev\n",
    "            ON (tweets.date - INTERVAL '1 day') = stock_prev.date\n",
    "        LEFT JOIN stock stock_prev_prev\n",
    "            ON (tweets.date - INTERVAL '2 day') = stock_prev_prev.date\n",
    "        LEFT JOIN stock stock_prev_prev_prev\n",
    "            ON (tweets.date - INTERVAL '3 day') = stock_prev_prev_prev.date\n",
    "        LEFT JOIN stock stock_next\n",
    "            ON (tweets.date + INTERVAL '1 day') = stock_next.date\n",
    "        LEFT JOIN stock stock_next_next\n",
    "            ON (tweets.date + INTERVAL '2 day') = stock_next_next.date\n",
    "        LEFT JOIN stock stock_next_next_next\n",
    "            ON (tweets.date + INTERVAL '3 day') = stock_next_next_next.date\n",
    "        WHERE tweets.date > '2011-01-01' AND tweets.tokenized_text != '{}'\n",
    "        ORDER BY tweets.date\n",
    "    \"\"\",\n",
    "    con=engine\n",
    ")\n",
    "\n",
    "tweets_price.dropna(inplace=True)\n",
    "\n",
    "#Computing difference between the stock price before the date of tweet and after the post. \n",
    "tweets_price['close_price_diff'] = tweets_price['next_day_close'] - tweets_price['prev_day_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c950af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>prev_day_close</th>\n",
       "      <th>next_day_close</th>\n",
       "      <th>close_price_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>{I made the volume on the Model S  http://t.co...</td>\n",
       "      <td>{made,volume,model,go,need,work,miniature,ston...</td>\n",
       "      <td>6.548</td>\n",
       "      <td>6.660</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-03</td>\n",
       "      <td>{That was a total non sequitur btw, Great Volt...</td>\n",
       "      <td>{total,non,sequitur,great,voltaire,quote,argua...</td>\n",
       "      <td>6.660</td>\n",
       "      <td>6.884</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>{Am reading a great biography of Ben Franklin ...</td>\n",
       "      <td>{reading,great,biography,ben,franklin,isaacson...</td>\n",
       "      <td>6.660</td>\n",
       "      <td>6.884</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>{Yum! Even better than deep fried butter:  htt...</td>\n",
       "      <td>{yum,even,better,deep,fried,butter,yeah,really...</td>\n",
       "      <td>5.580</td>\n",
       "      <td>5.554</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>{Model S options are out! Performance in red a...</td>\n",
       "      <td>{model,options,performance,red,black,deliver,c...</td>\n",
       "      <td>5.514</td>\n",
       "      <td>5.580</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_date                                         tweet_text  \\\n",
       "0 2011-12-01  {I made the volume on the Model S  http://t.co...   \n",
       "1 2011-12-03  {That was a total non sequitur btw, Great Volt...   \n",
       "2 2011-12-04  {Am reading a great biography of Ben Franklin ...   \n",
       "3 2011-12-21  {Yum! Even better than deep fried butter:  htt...   \n",
       "4 2011-12-22  {Model S options are out! Performance in red a...   \n",
       "\n",
       "                                        tweet_tokens  prev_day_close  \\\n",
       "0  {made,volume,model,go,need,work,miniature,ston...           6.548   \n",
       "1  {total,non,sequitur,great,voltaire,quote,argua...           6.660   \n",
       "2  {reading,great,biography,ben,franklin,isaacson...           6.660   \n",
       "3  {yum,even,better,deep,fried,butter,yeah,really...           5.580   \n",
       "4  {model,options,performance,red,black,deliver,c...           5.514   \n",
       "\n",
       "   next_day_close  close_price_diff  \n",
       "0           6.660             0.112  \n",
       "1           6.884             0.224  \n",
       "2           6.884             0.224  \n",
       "3           5.554            -0.026  \n",
       "4           5.580             0.066  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_price = tweets_price[tweets_price.tweet_tokens.str.count(',') > 1] # More than two words in tweet\n",
    "tweets_price.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96593c41",
   "metadata": {},
   "source": [
    "## A - Classification: Which tweets increase stock price vs decrease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f35a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up libraries for model\n",
    "\n",
    "#CountVectorizer = this takes in a list and counts how many times it appears\n",
    "#TfidfTransformer = frequency of word in a tweet as compared to other tweets\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression(C=0.01, random_state=1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3c89720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(tweets_price, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54d3a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up variables\n",
    "X_train = train_df.tweet_tokens.tolist()\n",
    "y_train = (train_df['close_price_diff'] > 0).astype(int).values\n",
    "X_test = test_df.tweet_tokens.tolist()\n",
    "y_test = (test_df['close_price_diff'] > 0).astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c6487e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(preprocessor=<function <lambda> at 0x7fde8dfe3820>,\n",
       "                                 tokenizer=<function <lambda> at 0x7fde8f7160d0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression(C=0.01, random_state=1))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify text data\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da6b4cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5736434108527132"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f67577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predicted probability\n",
    "predicted_proba_test = text_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8dac268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_positive_tweet</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>stock_price_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>0.553118</td>\n",
       "      <td>{Star Light, Star Bright  https://t.co/6CeTAZSXCO}</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>72.229980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0.552274</td>\n",
       "      <td>{Worth reading Life 3.0 by @Tegmark. AI will be the best or worst thing ever for humanity, so let’s get it right.  https://t.co/lT0uMH3ujZ}</td>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>1.503998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>0.551670</td>\n",
       "      <td>{RT @Tesla: Configurator now live in Hungary 🇭🇺 &amp;amp; Romania 🇷🇴, RT @SpaceX: SpaceX’s fifth high-altitude flight test of Starship from Starbase in Texas https://t.co/FnrXuHpsVj}</td>\n",
       "      <td>2021-05-14</td>\n",
       "      <td>5.140015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>0.551625</td>\n",
       "      <td>{About 5 mins from flight attempt, Starhopper flight currently tracking to 5pm Texas time for 150m / ~500ft hover test}</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>0.536003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.551546</td>\n",
       "      <td>{Over 1000 km should be possible in a 100D with the right tires  https://t.co/8czN3dVZE4}</td>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>2.074005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.551500</td>\n",
       "      <td>{US govt testing by @NHTSAgov finds Model X to be the safest SUV in history by significant margin  https://t.co/zAdb5FQPEI}</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>4.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>0.551442</td>\n",
       "      <td>{Regarding the meeting at the White House:  https://t.co/8b1XH4oW6h}</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>1.243999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.551121</td>\n",
       "      <td>{Fourth rocket arrives in the hangar. Aiming for first reflight in Sept/Oct.  https://t.co/TqW8d6Cc3U}</td>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>2.967999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.551069</td>\n",
       "      <td>{First test flight hop of our Grasshopper VTVL rocket!  http://t.co/oomI5vSB}</td>\n",
       "      <td>2012-09-22</td>\n",
       "      <td>0.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>0.550941</td>\n",
       "      <td>{Great progress by Starship Cape team. Started several months behind, but catching up fast. This will be a super fun race to orbit, moon &amp;amp; Mars!}</td>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>1.019997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      proba_positive_tweet  \\\n",
       "1543              0.553118   \n",
       "812               0.552274   \n",
       "1655              0.551670   \n",
       "1244              0.551625   \n",
       "769               0.551546   \n",
       "764               0.551500   \n",
       "706               0.551442   \n",
       "600               0.551121   \n",
       "116               0.551069   \n",
       "1231              0.550941   \n",
       "\n",
       "                                                                                                                                                                              tweet_text  \\\n",
       "1543                                                                                                                                  {Star Light, Star Bright  https://t.co/6CeTAZSXCO}   \n",
       "812                                          {Worth reading Life 3.0 by @Tegmark. AI will be the best or worst thing ever for humanity, so let’s get it right.  https://t.co/lT0uMH3ujZ}   \n",
       "1655  {RT @Tesla: Configurator now live in Hungary 🇭🇺 &amp; Romania 🇷🇴, RT @SpaceX: SpaceX’s fifth high-altitude flight test of Starship from Starbase in Texas https://t.co/FnrXuHpsVj}   \n",
       "1244                                                             {About 5 mins from flight attempt, Starhopper flight currently tracking to 5pm Texas time for 150m / ~500ft hover test}   \n",
       "769                                                                                            {Over 1000 km should be possible in a 100D with the right tires  https://t.co/8czN3dVZE4}   \n",
       "764                                                          {US govt testing by @NHTSAgov finds Model X to be the safest SUV in history by significant margin  https://t.co/zAdb5FQPEI}   \n",
       "706                                                                                                                 {Regarding the meeting at the White House:  https://t.co/8b1XH4oW6h}   \n",
       "600                                                                               {Fourth rocket arrives in the hangar. Aiming for first reflight in Sept/Oct.  https://t.co/TqW8d6Cc3U}   \n",
       "116                                                                                                        {First test flight hop of our Grasshopper VTVL rocket!  http://t.co/oomI5vSB}   \n",
       "1231                               {Great progress by Starship Cape team. Started several months behind, but catching up fast. This will be a super fun race to orbit, moon &amp; Mars!}   \n",
       "\n",
       "     tweet_date  stock_price_change  \n",
       "1543 2020-12-17           72.229980  \n",
       "812  2017-08-29            1.503998  \n",
       "1655 2021-05-14            5.140015  \n",
       "1244 2019-08-26            0.536003  \n",
       "769  2017-06-21            2.074005  \n",
       "764  2017-06-13            4.330002  \n",
       "706  2017-02-03            1.243999  \n",
       "600  2016-06-07            2.967999  \n",
       "116  2012-09-22            0.128000  \n",
       "1231 2019-08-06            1.019997  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding results into DataFrame\n",
    "results_test = pd.DataFrame({\n",
    "    'proba_positive_tweet': predicted_proba_test,\n",
    "    'tweet_text': test_df['tweet_text'],\n",
    "    'tweet_date': test_df['tweet_date'],\n",
    "    'stock_price_change': test_df['close_price_diff'],\n",
    "}).sort_values('proba_positive_tweet', ascending=False)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "results_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9296f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test.to_csv('data/results_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-vs-stock",
   "language": "python",
   "name": "twitter-vs-stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
