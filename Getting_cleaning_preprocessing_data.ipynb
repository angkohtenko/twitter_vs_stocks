{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29d489e",
   "metadata": {},
   "source": [
    "# (1) Twitter Data\n",
    "## (1.1) Getting Twitter data 2021 from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5765ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from path import Path\n",
    "from twarc import Twarc2, expansions\n",
    "import json\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73f8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import bearer_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b804e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Twarc2(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42efd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'elonmusk'\n",
    "posts_dict = {\n",
    "    'date':[],\n",
    "    'text':[],\n",
    "    'like_count':[],\n",
    "    'reply_count':[],\n",
    "    'retweet_count':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bde4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull posts from Twitter and create a dictionary\n",
    "user_timeline = client.timeline(user=user, exclude_replies=True, start_time=datetime.datetime(2021,1,1, 0, 0, 0) )\n",
    "for page in user_timeline:\n",
    "    result = expansions.flatten(page)\n",
    "    for tweet in result:\n",
    "        posts_dict['date'].append(tweet['created_at'])\n",
    "        posts_dict['text'].append(tweet['text'])\n",
    "        posts_dict['like_count'].append(tweet['public_metrics']['like_count'])\n",
    "        posts_dict['reply_count'].append(tweet['public_metrics']['reply_count'])\n",
    "        posts_dict['retweet_count'].append(tweet['public_metrics']['retweet_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159622c3",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       date  \\\n",
       "0  2021-07-21T19:55:51.000Z   \n",
       "1  2021-07-21T11:14:53.000Z   \n",
       "2  2021-07-20T01:22:56.000Z   \n",
       "3  2021-07-20T00:07:03.000Z   \n",
       "4  2021-07-19T17:44:50.000Z   \n",
       "\n",
       "                                                text  like_count  reply_count  \\\n",
       "0  RT @SpaceX: Dragon has autonomously re-docked ...           0            0   \n",
       "1  RT @NASA: LIVE: The @SpaceX Crew Dragon Endeav...           0            0   \n",
       "2  RT @SpaceX: First static fire test of Super He...           0            0   \n",
       "3  Full test duration firing of 3 Raptors on Supe...      121963         8087   \n",
       "4  RT @inspiration4x: Generosity, Prosperity, Lea...           0            0   \n",
       "\n",
       "   retweet_count  \n",
       "0           3177  \n",
       "1           2280  \n",
       "2           9346  \n",
       "3           6230  \n",
       "4           1967  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-07-21T19:55:51.000Z</td>\n      <td>RT @SpaceX: Dragon has autonomously re-docked ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3177</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-07-21T11:14:53.000Z</td>\n      <td>RT @NASA: LIVE: The @SpaceX Crew Dragon Endeav...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2280</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-07-20T01:22:56.000Z</td>\n      <td>RT @SpaceX: First static fire test of Super He...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9346</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-07-20T00:07:03.000Z</td>\n      <td>Full test duration firing of 3 Raptors on Supe...</td>\n      <td>121963</td>\n      <td>8087</td>\n      <td>6230</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-07-19T17:44:50.000Z</td>\n      <td>RT @inspiration4x: Generosity, Prosperity, Lea...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1967</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# convert dictionary of posts to dataframe\n",
    "twitter_2021 = pd.DataFrame.from_dict(posts_dict)\n",
    "twitter_2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          date                                               text  like_count  \\\n",
       "439 2021-01-07  This is called the domino effect https://t.co/...      366241   \n",
       "440 2021-01-04  Because of the large footprint, it may seem fl...       57807   \n",
       "441 2021-01-04  Snow falling on Giga Berlin https://t.co/eTXMt...      148307   \n",
       "442 2021-01-02  So proud of the Tesla team for achieving this ...      109731   \n",
       "443 2021-01-02  RT @Tesla: In 2020, we produced and delivered ...           0   \n",
       "\n",
       "     reply_count  retweet_count  \n",
       "439         4495          37489  \n",
       "440         1386           1069  \n",
       "441         3642           6860  \n",
       "442         4145           6227  \n",
       "443            0           6258  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>439</th>\n      <td>2021-01-07</td>\n      <td>This is called the domino effect https://t.co/...</td>\n      <td>366241</td>\n      <td>4495</td>\n      <td>37489</td>\n    </tr>\n    <tr>\n      <th>440</th>\n      <td>2021-01-04</td>\n      <td>Because of the large footprint, it may seem fl...</td>\n      <td>57807</td>\n      <td>1386</td>\n      <td>1069</td>\n    </tr>\n    <tr>\n      <th>441</th>\n      <td>2021-01-04</td>\n      <td>Snow falling on Giga Berlin https://t.co/eTXMt...</td>\n      <td>148307</td>\n      <td>3642</td>\n      <td>6860</td>\n    </tr>\n    <tr>\n      <th>442</th>\n      <td>2021-01-02</td>\n      <td>So proud of the Tesla team for achieving this ...</td>\n      <td>109731</td>\n      <td>4145</td>\n      <td>6227</td>\n    </tr>\n    <tr>\n      <th>443</th>\n      <td>2021-01-02</td>\n      <td>RT @Tesla: In 2020, we produced and delivered ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6258</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# convert date to datetime datatype\n",
    "twitter_2021['date'] = pd.to_datetime(twitter_2021['date']).dt.date.astype('datetime64')\n",
    "twitter_2021.tail()"
   ]
  },
  {
   "source": [
    "## (1.2) Getting Twitter data 2011 - 2020 from archive"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                   id      conversation_id    created_at  \\\n",
       "0           0  1343644462036086785  1343320495127633920  1.609185e+12   \n",
       "1           1  1343619610617077760  1343386617294295040  1.609179e+12   \n",
       "2           2  1343608616960491521  1343576442722893825  1.609176e+12   \n",
       "3           3  1343608530998153222  1343320495127633920  1.609176e+12   \n",
       "4           4  1343431408052662273  1343043963096326147  1.609134e+12   \n",
       "\n",
       "                  date  timezone  place  \\\n",
       "0  2020-12-28 19:46:18         0    NaN   \n",
       "1  2020-12-28 18:07:33         0    NaN   \n",
       "2  2020-12-28 17:23:51         0    NaN   \n",
       "3  2020-12-28 17:23:31         0    NaN   \n",
       "4  2020-12-28 05:39:42         0    NaN   \n",
       "\n",
       "                                               tweet language hashtags  ...  \\\n",
       "0  Entertainment will be critical when cars drive...       en       []  ...   \n",
       "1  @kimpaquette Just meeting with Larry Ellison t...       en       []  ...   \n",
       "2                        @richierichhhhh_ Absolutely       en       []  ...   \n",
       "3  What should Tesla do with in-car gaming in an ...       en       []  ...   \n",
       "4                          @PPathole @WSJ Absolutely       en       []  ...   \n",
       "\n",
       "  geo  source  user_rt_id user_rt retweet_id  \\\n",
       "0 NaN     NaN         NaN     NaN        NaN   \n",
       "1 NaN     NaN         NaN     NaN        NaN   \n",
       "2 NaN     NaN         NaN     NaN        NaN   \n",
       "3 NaN     NaN         NaN     NaN        NaN   \n",
       "4 NaN     NaN         NaN     NaN        NaN   \n",
       "\n",
       "                                            reply_to  retweet_date translate  \\\n",
       "0                                                 []           NaN       NaN   \n",
       "1  [{'screen_name': 'kimpaquette', 'name': 'Kim P...           NaN       NaN   \n",
       "2  [{'screen_name': 'richierichhhhh_', 'name': 'R...           NaN       NaN   \n",
       "3                                                 []           NaN       NaN   \n",
       "4  [{'screen_name': 'PPathole', 'name': 'Pranay P...           NaN       NaN   \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        NaN  \n",
       "4       NaN        NaN  \n",
       "\n",
       "[5 rows x 39 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>conversation_id</th>\n      <th>created_at</th>\n      <th>date</th>\n      <th>timezone</th>\n      <th>place</th>\n      <th>tweet</th>\n      <th>language</th>\n      <th>hashtags</th>\n      <th>...</th>\n      <th>geo</th>\n      <th>source</th>\n      <th>user_rt_id</th>\n      <th>user_rt</th>\n      <th>retweet_id</th>\n      <th>reply_to</th>\n      <th>retweet_date</th>\n      <th>translate</th>\n      <th>trans_src</th>\n      <th>trans_dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1343644462036086785</td>\n      <td>1343320495127633920</td>\n      <td>1.609185e+12</td>\n      <td>2020-12-28 19:46:18</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>Entertainment will be critical when cars drive...</td>\n      <td>en</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1343619610617077760</td>\n      <td>1343386617294295040</td>\n      <td>1.609179e+12</td>\n      <td>2020-12-28 18:07:33</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>@kimpaquette Just meeting with Larry Ellison t...</td>\n      <td>en</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[{'screen_name': 'kimpaquette', 'name': 'Kim P...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1343608616960491521</td>\n      <td>1343576442722893825</td>\n      <td>1.609176e+12</td>\n      <td>2020-12-28 17:23:51</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>@richierichhhhh_ Absolutely</td>\n      <td>en</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[{'screen_name': 'richierichhhhh_', 'name': 'R...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1343608530998153222</td>\n      <td>1343320495127633920</td>\n      <td>1.609176e+12</td>\n      <td>2020-12-28 17:23:31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>What should Tesla do with in-car gaming in an ...</td>\n      <td>en</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1343431408052662273</td>\n      <td>1343043963096326147</td>\n      <td>1.609134e+12</td>\n      <td>2020-12-28 05:39:42</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>@PPathole @WSJ Absolutely</td>\n      <td>en</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[{'screen_name': 'PPathole', 'name': 'Pranay P...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# load twitter data from csv file\n",
    "file_to_load = os.path.join('Data', 'elon_musk_tweets_2011-2020.csv')\n",
    "twitter_archive = pd.read_csv(file_to_load)\n",
    "twitter_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         date                                               text  like_count  \\\n",
       "0  2020-12-28  Entertainment will be critical when cars drive...       55085   \n",
       "3  2020-12-28  What should Tesla do with in-car gaming in an ...       33830   \n",
       "6  2020-12-27  Try playing Polytopia in your Tesla! Great gam...      148037   \n",
       "34 2020-12-25  Change your horn sound to 🐐, 🐍🎷, 💨 or holiday ...      187368   \n",
       "35 2020-12-25  Merry Christmas &amp; happy holidays! 🎁  https...      236833   \n",
       "\n",
       "    reply_count  retweet_count  \n",
       "0          2922           2611  \n",
       "3          6932            884  \n",
       "6          5355           4186  \n",
       "34         5373           6983  \n",
       "35         7496          13288  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-12-28</td>\n      <td>Entertainment will be critical when cars drive...</td>\n      <td>55085</td>\n      <td>2922</td>\n      <td>2611</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-12-28</td>\n      <td>What should Tesla do with in-car gaming in an ...</td>\n      <td>33830</td>\n      <td>6932</td>\n      <td>884</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2020-12-27</td>\n      <td>Try playing Polytopia in your Tesla! Great gam...</td>\n      <td>148037</td>\n      <td>5355</td>\n      <td>4186</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>2020-12-25</td>\n      <td>Change your horn sound to 🐐, 🐍🎷, 💨 or holiday ...</td>\n      <td>187368</td>\n      <td>5373</td>\n      <td>6983</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>2020-12-25</td>\n      <td>Merry Christmas &amp;amp; happy holidays! 🎁  https...</td>\n      <td>236833</td>\n      <td>7496</td>\n      <td>13288</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# select and rename columns\n",
    "twitter_archive_clean = twitter_archive[['date', 'tweet', 'nlikes', 'nreplies', 'nretweets']]\\\n",
    "                            .loc[(twitter_archive['reply_to'] == '[]') & (twitter_archive['retweet'] == False)]\n",
    "twitter_archive_clean.columns=['date', 'text', 'like_count', 'reply_count', 'retweet_count']\n",
    "\n",
    "# convert date to datetime datatype\n",
    "twitter_archive_clean['date'] = pd.to_datetime(twitter_archive_clean['date']).dt.date.astype('datetime64')\n",
    "\n",
    "# drop last row with 1 tweet in 2010\n",
    "twitter_archive_clean.drop(twitter_archive_clean.tail(1).index,inplace=True)\n",
    "\n",
    "twitter_archive_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c62e0",
   "metadata": {},
   "source": [
    "## (1.3) Clean the twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 4629 entries, 0 to 11715\nData columns (total 5 columns):\n #   Column         Non-Null Count  Dtype         \n---  ------         --------------  -----         \n 0   date           4629 non-null   datetime64[ns]\n 1   text           4629 non-null   object        \n 2   like_count     4629 non-null   int64         \n 3   reply_count    4629 non-null   int64         \n 4   retweet_count  4629 non-null   int64         \ndtypes: datetime64[ns](1), int64(3), object(1)\nmemory usage: 217.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# concatenate 2 datasets to get tweets from 2011 to 2021\n",
    "twitter_df_merged = pd.concat([twitter_2021, twitter_archive_clean])\n",
    "twitter_df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "971be6ce",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            date                                               text  \\\n",
       "0     2021-07-21  RT @SpaceX: Dragon has autonomously re-docked ...   \n",
       "1     2021-07-21  RT @NASA: LIVE: The @SpaceX Crew Dragon Endeav...   \n",
       "2     2021-07-20  RT @SpaceX: First static fire test of Super He...   \n",
       "3     2021-07-20  Full test duration firing of 3 Raptors on Supe...   \n",
       "4     2021-07-19  RT @inspiration4x: Generosity, Prosperity, Lea...   \n",
       "...          ...                                                ...   \n",
       "11711 2011-12-04  Am reading a great biography of Ben Franklin b...   \n",
       "11712 2011-12-03                  That was a total non sequitur btw   \n",
       "11713 2011-12-03  Great Voltaire quote, arguably better than Twa...   \n",
       "11714 2011-12-01  I made the volume on the Model S  http://t.co/...   \n",
       "11715 2011-12-01  Went to Iceland on Sat to ride bumper cars on ...   \n",
       "\n",
       "       like_count  reply_count  retweet_count  \n",
       "0               0            0           3177  \n",
       "1               0            0           2280  \n",
       "2               0            0           9346  \n",
       "3          121963         8087           6230  \n",
       "4               0            0           1967  \n",
       "...           ...          ...            ...  \n",
       "11711          65           17              9  \n",
       "11712          53           31              6  \n",
       "11713          29            7             25  \n",
       "11714          78           31              9  \n",
       "11715         189           32             15  \n",
       "\n",
       "[4629 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-07-21</td>\n      <td>RT @SpaceX: Dragon has autonomously re-docked ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3177</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-07-21</td>\n      <td>RT @NASA: LIVE: The @SpaceX Crew Dragon Endeav...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2280</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-07-20</td>\n      <td>RT @SpaceX: First static fire test of Super He...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9346</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-07-20</td>\n      <td>Full test duration firing of 3 Raptors on Supe...</td>\n      <td>121963</td>\n      <td>8087</td>\n      <td>6230</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-07-19</td>\n      <td>RT @inspiration4x: Generosity, Prosperity, Lea...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1967</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11711</th>\n      <td>2011-12-04</td>\n      <td>Am reading a great biography of Ben Franklin b...</td>\n      <td>65</td>\n      <td>17</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>11712</th>\n      <td>2011-12-03</td>\n      <td>That was a total non sequitur btw</td>\n      <td>53</td>\n      <td>31</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>11713</th>\n      <td>2011-12-03</td>\n      <td>Great Voltaire quote, arguably better than Twa...</td>\n      <td>29</td>\n      <td>7</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>11714</th>\n      <td>2011-12-01</td>\n      <td>I made the volume on the Model S  http://t.co/...</td>\n      <td>78</td>\n      <td>31</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>11715</th>\n      <td>2011-12-01</td>\n      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n      <td>189</td>\n      <td>32</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n<p>4629 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Drop the NaNs\n",
    "twitter_df_merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all tweets for analysis in Tableau\n",
    "twitter_df_merged.to_csv('Data/tweets_data_2010_2020_ungrouped.csv', index=False)"
   ]
  },
  {
   "source": [
    "## (1.4) Preprocessing the Twitter data\n",
    "\n",
    "**Preprocess the data by making it all lowercase. Remove a reasonable set of stopwords from the dataset and tokenize. Then, report the 10 most common words and their count. We need to iterate this process, adding some stop words as we understand the structure of the data. Justify additional stop words we've added.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from datetime import datetime\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b731df31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# group tweets that posted at the same day\n",
    "def f(x):\n",
    "     return pd.Series(dict(like_count = x['like_count'].sum(),\n",
    "                        reply_count = x['reply_count'].sum(),\n",
    "                        retweet_count = x['retweet_count'].sum(),\n",
    "                        text = \"{%s}\" % ', '.join(x['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d661c8a",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date  like_count  reply_count  retweet_count  \\\n",
       "0 2011-12-01         267           63             24   \n",
       "1 2011-12-03          82           38             31   \n",
       "2 2011-12-04          65           17              9   \n",
       "3 2011-12-21        1330           87            597   \n",
       "4 2011-12-22        1349          132            206   \n",
       "\n",
       "                                                text  \n",
       "0  {I made the volume on the Model S  http://t.co...  \n",
       "1  {That was a total non sequitur btw, Great Volt...  \n",
       "2  {Am reading a great biography of Ben Franklin ...  \n",
       "3  {Yum! Even better than deep fried butter:  htt...  \n",
       "4  {Model S options are out! Performance in red a...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-12-01</td>\n      <td>267</td>\n      <td>63</td>\n      <td>24</td>\n      <td>{I made the volume on the Model S  http://t.co...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-12-03</td>\n      <td>82</td>\n      <td>38</td>\n      <td>31</td>\n      <td>{That was a total non sequitur btw, Great Volt...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-12-04</td>\n      <td>65</td>\n      <td>17</td>\n      <td>9</td>\n      <td>{Am reading a great biography of Ben Franklin ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-12-21</td>\n      <td>1330</td>\n      <td>87</td>\n      <td>597</td>\n      <td>{Yum! Even better than deep fried butter:  htt...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-12-22</td>\n      <td>1349</td>\n      <td>132</td>\n      <td>206</td>\n      <td>{Model S options are out! Performance in red a...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "twitter_df_merged = twitter_df_merged.groupby('date').apply(f).reset_index()\n",
    "twitter_df_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "date             1724\n",
       "like_count       1724\n",
       "reply_count      1724\n",
       "retweet_count    1724\n",
       "text             1724\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "twitter_df_merged.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = twitter_df_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0fd768a",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ziza/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date  like_count  reply_count  retweet_count  \\\n",
       "0 2011-12-01         267           63             24   \n",
       "1 2011-12-03          82           38             31   \n",
       "2 2011-12-04          65           17              9   \n",
       "3 2011-12-21        1330           87            597   \n",
       "4 2011-12-22        1349          132            206   \n",
       "\n",
       "                                                text  \\\n",
       "0  {I made the volume on the Model S  http://t.co...   \n",
       "1  {That was a total non sequitur btw, Great Volt...   \n",
       "2  {Am reading a great biography of Ben Franklin ...   \n",
       "3  {Yum! Even better than deep fried butter:  htt...   \n",
       "4  {Model S options are out! Performance in red a...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  {i made the volume on the model s go to 11. no...   \n",
       "1  {that was a total non sequitur btw, great volt...   \n",
       "2  {am reading a great biography of ben franklin ...   \n",
       "3  {yum! even better than deep fried butter: yeah...   \n",
       "4  {model s options are out! performance in red a...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [made, volume, model, go, need, work, miniatur...  \n",
       "1  [total, non, sequitur, great, voltaire, quote,...  \n",
       "2  [reading, great, biography, ben, franklin, isa...  \n",
       "3  [yum, even, better, deep, fried, butter, yeah,...  \n",
       "4  [model, options, performance, red, black, deli...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n      <th>text</th>\n      <th>preprocessed_text</th>\n      <th>tokenized_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-12-01</td>\n      <td>267</td>\n      <td>63</td>\n      <td>24</td>\n      <td>{I made the volume on the Model S  http://t.co...</td>\n      <td>{i made the volume on the model s go to 11. no...</td>\n      <td>[made, volume, model, go, need, work, miniatur...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-12-03</td>\n      <td>82</td>\n      <td>38</td>\n      <td>31</td>\n      <td>{That was a total non sequitur btw, Great Volt...</td>\n      <td>{that was a total non sequitur btw, great volt...</td>\n      <td>[total, non, sequitur, great, voltaire, quote,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-12-04</td>\n      <td>65</td>\n      <td>17</td>\n      <td>9</td>\n      <td>{Am reading a great biography of Ben Franklin ...</td>\n      <td>{am reading a great biography of ben franklin ...</td>\n      <td>[reading, great, biography, ben, franklin, isa...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-12-21</td>\n      <td>1330</td>\n      <td>87</td>\n      <td>597</td>\n      <td>{Yum! Even better than deep fried butter:  htt...</td>\n      <td>{yum! even better than deep fried butter: yeah...</td>\n      <td>[yum, even, better, deep, fried, butter, yeah,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-12-22</td>\n      <td>1349</td>\n      <td>132</td>\n      <td>206</td>\n      <td>{Model S options are out! Performance in red a...</td>\n      <td>{model s options are out! performance in red a...</td>\n      <td>[model, options, performance, red, black, deli...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Data Pre-processing and make the tweets all lowercase and remove stopwords.\n",
    "# lower the tweets\n",
    "twitter_df['preprocessed_text'] = twitter_df['text'].str.lower()\n",
    "\n",
    "# remove apostrophe from words and url\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"('[a-z]+)\\s\", \" \", row) for row in twitter_df['preprocessed_text']]\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"(')\\s\", \" \", row) for row in twitter_df['preprocessed_text']]\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"(?:https:\\/\\/\\S+)\\s\", \"\", row) for row in twitter_df['preprocessed_text']]\n",
    "\n",
    "                                      \n",
    "# filter out rest URLs\n",
    "url_re = '(?:https?:\\/\\/)?(?:[^?\\/\\s]+[?\\/])(.*)'\n",
    "twitter_df['preprocessed_text'] = twitter_df['preprocessed_text'].apply(lambda row: ' '.join([word for word in row.split() if (not re.match(url_re, word))]))\n",
    "\n",
    "# tokenize the tweets\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z]\\w+\\'?\\w*')\n",
    "twitter_df['tokenized_text'] = twitter_df['preprocessed_text'].apply(lambda row: tokenizer.tokenize(row))\n",
    "\n",
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# apply stemming\n",
    "twitter_df['preprocessed_text'] = [porter.stem(row) for row in twitter_df['preprocessed_text']]   \n",
    "\n",
    "# filter out stop words\n",
    "en_stop_words = nltk.corpus.stopwords.words('english')\n",
    "additional_stop_words =['amp', 'rt', 'th','co', 're', 've', 'kim', 'daca', 'us', 'it', 'th', 'you', 'haha', 'st', 'et', 'so', 'iii', 'also', 've', 'la', 're', 'the', 'https', 'wow', 'actually', 'due', 'ft', 'pcr', 'via', 'am', 'gt', 'com', 'since', 'in', 'me', 'and', 'btw', 'yesterday', 'ii', 'inu', 'on', 'http', 'to', 'vs', 'rd', 'ur', 'of', 'bs', 'km', 'est', 'em', 'lz', 'kms', 'aft', 'nd',  'here’s', 're', 'mqxfakpzf' 'mph', 'ht', 'etc', 'dm', 'doo']\n",
    "en_stop_words.extend(additional_stop_words)\n",
    "\n",
    "twitter_df['tokenized_text'] = twitter_df['tokenized_text'].apply(lambda row: [word for word in row if (not word in en_stop_words)])\n",
    "\n",
    "df_tweets_clean = twitter_df.copy()\n",
    "df_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caba4f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date                                               text  \\\n",
       "0 2011-12-01  {I made the volume on the Model S  http://t.co...   \n",
       "1 2011-12-03  {That was a total non sequitur btw, Great Volt...   \n",
       "2 2011-12-04  {Am reading a great biography of Ben Franklin ...   \n",
       "3 2011-12-21  {Yum! Even better than deep fried butter:  htt...   \n",
       "4 2011-12-22  {Model S options are out! Performance in red a...   \n",
       "5 2011-12-24  {The Russians are having some challenges with ...   \n",
       "6 2011-12-26  {Walked around a neighborhood recently rebuilt...   \n",
       "7 2011-12-27  {If you ever wanted to know the *real* truth a...   \n",
       "8 2011-12-28                             {@TheOnion So true :)}   \n",
       "9 2011-12-29  {Am not saying that is *necessarily* good or b...   \n",
       "\n",
       "                                      tokenized_text  like_count  reply_count  \\\n",
       "0  [made, volume, model, go, need, work, miniatur...         267           63   \n",
       "1  [total, non, sequitur, great, voltaire, quote,...          82           38   \n",
       "2  [reading, great, biography, ben, franklin, isa...          65           17   \n",
       "3  [yum, even, better, deep, fried, butter, yeah,...        1330           87   \n",
       "4  [model, options, performance, red, black, deli...        1349          132   \n",
       "5  [russians, challenges, rockets, many, engineer...      117113         1370   \n",
       "6  [walked, around, neighborhood, recently, rebui...         558          102   \n",
       "7  [ever, wanted, know, real, truth, moon, landin...          39           13   \n",
       "8                                   [theonion, true]          12            7   \n",
       "9  [saying, necessarily, good, bad, reality, forc...         187           39   \n",
       "\n",
       "   retweet_count  \n",
       "0             24  \n",
       "1             31  \n",
       "2              9  \n",
       "3            597  \n",
       "4            206  \n",
       "5           8434  \n",
       "6            171  \n",
       "7             34  \n",
       "8              1  \n",
       "9             41  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>tokenized_text</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-12-01</td>\n      <td>{I made the volume on the Model S  http://t.co...</td>\n      <td>[made, volume, model, go, need, work, miniatur...</td>\n      <td>267</td>\n      <td>63</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-12-03</td>\n      <td>{That was a total non sequitur btw, Great Volt...</td>\n      <td>[total, non, sequitur, great, voltaire, quote,...</td>\n      <td>82</td>\n      <td>38</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-12-04</td>\n      <td>{Am reading a great biography of Ben Franklin ...</td>\n      <td>[reading, great, biography, ben, franklin, isa...</td>\n      <td>65</td>\n      <td>17</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-12-21</td>\n      <td>{Yum! Even better than deep fried butter:  htt...</td>\n      <td>[yum, even, better, deep, fried, butter, yeah,...</td>\n      <td>1330</td>\n      <td>87</td>\n      <td>597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-12-22</td>\n      <td>{Model S options are out! Performance in red a...</td>\n      <td>[model, options, performance, red, black, deli...</td>\n      <td>1349</td>\n      <td>132</td>\n      <td>206</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2011-12-24</td>\n      <td>{The Russians are having some challenges with ...</td>\n      <td>[russians, challenges, rockets, many, engineer...</td>\n      <td>117113</td>\n      <td>1370</td>\n      <td>8434</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2011-12-26</td>\n      <td>{Walked around a neighborhood recently rebuilt...</td>\n      <td>[walked, around, neighborhood, recently, rebui...</td>\n      <td>558</td>\n      <td>102</td>\n      <td>171</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2011-12-27</td>\n      <td>{If you ever wanted to know the *real* truth a...</td>\n      <td>[ever, wanted, know, real, truth, moon, landin...</td>\n      <td>39</td>\n      <td>13</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2011-12-28</td>\n      <td>{@TheOnion So true :)}</td>\n      <td>[theonion, true]</td>\n      <td>12</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2011-12-29</td>\n      <td>{Am not saying that is *necessarily* good or b...</td>\n      <td>[saying, necessarily, good, bad, reality, forc...</td>\n      <td>187</td>\n      <td>39</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df_tweets_clean = df_tweets_clean[['date', 'text', 'tokenized_text', 'like_count', 'reply_count', 'retweet_count']]\n",
    "df_tweets_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6338deb5",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8197"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# count unique words\n",
    "def get_most_freq_words(str, n=None):\n",
    "    vect = CountVectorizer().fit(str)\n",
    "    bag_of_words = vect.transform(str)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
    "    return freq[:n]\n",
    "  \n",
    "len(get_most_freq_words([ word for tweet in df_tweets_clean.tokenized_text for word in tweet]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "effaa3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.to_csv('data/tweets_data_2010_2020.csv', index=False)"
   ]
  },
  {
   "source": [
    "## (1.5) Upload dataset to SQL Database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import psycopg2\n",
    "from config import user, password, hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{hostname}/twitter_vs_stocks')\n",
    "\n",
    "# Use the Inspector to explore the database\n",
    "inspector = inspect(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.to_sql('tweets_text', engine, if_exists ='replace',method='multi', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf788124",
   "metadata": {},
   "source": [
    "# (2 ) Stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c8153",
   "metadata": {},
   "source": [
    "## (2.1) Getting the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5ee54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "725dce38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           date        open        high         low       close    adjclose  \\\n",
       "0    2011-01-03    5.368000    5.400000    5.180000    5.324000    5.324000   \n",
       "1    2011-01-04    5.332000    5.390000    5.204000    5.334000    5.334000   \n",
       "2    2011-01-05    5.296000    5.380000    5.238000    5.366000    5.366000   \n",
       "3    2011-01-06    5.366000    5.600000    5.362000    5.576000    5.576000   \n",
       "4    2011-01-07    5.600000    5.716000    5.580000    5.648000    5.648000   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "2652 2021-07-19  629.890015  647.200012  621.289978  646.219971  646.219971   \n",
       "2653 2021-07-20  651.989990  662.390015  640.500000  660.500000  660.500000   \n",
       "2654 2021-07-21  659.609985  664.859985  650.289978  655.289978  655.289978   \n",
       "2655 2021-07-22  656.440002  662.169983  644.599976  649.260010  649.260010   \n",
       "2656 2021-07-23  646.359985  647.210022  637.300110  644.590027  644.590027   \n",
       "\n",
       "        volume ticker  \n",
       "0      6415000   TSLA  \n",
       "1      5937000   TSLA  \n",
       "2      7233500   TSLA  \n",
       "3     10306000   TSLA  \n",
       "4     11239500   TSLA  \n",
       "...        ...    ...  \n",
       "2652  21297100   TSLA  \n",
       "2653  15442700   TSLA  \n",
       "2654  13910800   TSLA  \n",
       "2655  15075600   TSLA  \n",
       "2656  10336641   TSLA  \n",
       "\n",
       "[2657 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adjclose</th>\n      <th>volume</th>\n      <th>ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-03</td>\n      <td>5.368000</td>\n      <td>5.400000</td>\n      <td>5.180000</td>\n      <td>5.324000</td>\n      <td>5.324000</td>\n      <td>6415000</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-04</td>\n      <td>5.332000</td>\n      <td>5.390000</td>\n      <td>5.204000</td>\n      <td>5.334000</td>\n      <td>5.334000</td>\n      <td>5937000</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-05</td>\n      <td>5.296000</td>\n      <td>5.380000</td>\n      <td>5.238000</td>\n      <td>5.366000</td>\n      <td>5.366000</td>\n      <td>7233500</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-01-06</td>\n      <td>5.366000</td>\n      <td>5.600000</td>\n      <td>5.362000</td>\n      <td>5.576000</td>\n      <td>5.576000</td>\n      <td>10306000</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-01-07</td>\n      <td>5.600000</td>\n      <td>5.716000</td>\n      <td>5.580000</td>\n      <td>5.648000</td>\n      <td>5.648000</td>\n      <td>11239500</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2652</th>\n      <td>2021-07-19</td>\n      <td>629.890015</td>\n      <td>647.200012</td>\n      <td>621.289978</td>\n      <td>646.219971</td>\n      <td>646.219971</td>\n      <td>21297100</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>2653</th>\n      <td>2021-07-20</td>\n      <td>651.989990</td>\n      <td>662.390015</td>\n      <td>640.500000</td>\n      <td>660.500000</td>\n      <td>660.500000</td>\n      <td>15442700</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>2654</th>\n      <td>2021-07-21</td>\n      <td>659.609985</td>\n      <td>664.859985</td>\n      <td>650.289978</td>\n      <td>655.289978</td>\n      <td>655.289978</td>\n      <td>13910800</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>2655</th>\n      <td>2021-07-22</td>\n      <td>656.440002</td>\n      <td>662.169983</td>\n      <td>644.599976</td>\n      <td>649.260010</td>\n      <td>649.260010</td>\n      <td>15075600</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>2656</th>\n      <td>2021-07-23</td>\n      <td>646.359985</td>\n      <td>647.210022</td>\n      <td>637.300110</td>\n      <td>644.590027</td>\n      <td>644.590027</td>\n      <td>10336641</td>\n      <td>TSLA</td>\n    </tr>\n  </tbody>\n</table>\n<p>2657 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# historical daily data from Yahoo finance\n",
    "tesla_df = get_data(\"tsla\", start_date = '2011-01-01', end_date = None, index_as_date = False, interval=\"1d\")\n",
    "tesla_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e57be6",
   "metadata": {},
   "source": [
    "## (2.2) Clean the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72eba53e",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date   open   high    low  close    volume\n",
       "0 2011-01-03  5.368  5.400  5.180  5.324   6415000\n",
       "1 2011-01-04  5.332  5.390  5.204  5.334   5937000\n",
       "2 2011-01-05  5.296  5.380  5.238  5.366   7233500\n",
       "3 2011-01-06  5.366  5.600  5.362  5.576  10306000\n",
       "4 2011-01-07  5.600  5.716  5.580  5.648  11239500"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-03</td>\n      <td>5.368</td>\n      <td>5.400</td>\n      <td>5.180</td>\n      <td>5.324</td>\n      <td>6415000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-04</td>\n      <td>5.332</td>\n      <td>5.390</td>\n      <td>5.204</td>\n      <td>5.334</td>\n      <td>5937000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-05</td>\n      <td>5.296</td>\n      <td>5.380</td>\n      <td>5.238</td>\n      <td>5.366</td>\n      <td>7233500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-01-06</td>\n      <td>5.366</td>\n      <td>5.600</td>\n      <td>5.362</td>\n      <td>5.576</td>\n      <td>10306000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-01-07</td>\n      <td>5.600</td>\n      <td>5.716</td>\n      <td>5.580</td>\n      <td>5.648</td>\n      <td>11239500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# Drop adjclose column\n",
    "tesla_df = tesla_df.drop(columns=[\"adjclose\", \"ticker\"])\n",
    "tesla_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fff742f3",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "date      datetime64[ns]\n",
       "open             float64\n",
       "high             float64\n",
       "low              float64\n",
       "close            float64\n",
       "volume             int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Determine data types for each column\n",
    "tesla_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc19c0",
   "metadata": {},
   "source": [
    "## (2.3) Preprocessing the Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f772a94",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date   open   high    low  close    volume  change\n",
       "0 2011-01-03  5.368  5.400  5.180  5.324   6415000     NaN\n",
       "1 2011-01-04  5.332  5.390  5.204  5.334   5937000   0.010\n",
       "2 2011-01-05  5.296  5.380  5.238  5.366   7233500   0.032\n",
       "3 2011-01-06  5.366  5.600  5.362  5.576  10306000   0.210\n",
       "4 2011-01-07  5.600  5.716  5.580  5.648  11239500   0.072\n",
       "5 2011-01-10  5.634  5.736  5.610  5.690   6713500   0.042\n",
       "6 2011-01-11  5.718  5.742  5.384  5.392   8551000  -0.298\n",
       "7 2011-01-12  5.402  5.480  5.304  5.392   4822000   0.000\n",
       "8 2011-01-13  5.392  5.394  5.232  5.244   3618000  -0.148\n",
       "9 2011-01-14  5.230  5.316  5.122  5.150   5960000  -0.094"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>change</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-03</td>\n      <td>5.368</td>\n      <td>5.400</td>\n      <td>5.180</td>\n      <td>5.324</td>\n      <td>6415000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-04</td>\n      <td>5.332</td>\n      <td>5.390</td>\n      <td>5.204</td>\n      <td>5.334</td>\n      <td>5937000</td>\n      <td>0.010</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-05</td>\n      <td>5.296</td>\n      <td>5.380</td>\n      <td>5.238</td>\n      <td>5.366</td>\n      <td>7233500</td>\n      <td>0.032</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-01-06</td>\n      <td>5.366</td>\n      <td>5.600</td>\n      <td>5.362</td>\n      <td>5.576</td>\n      <td>10306000</td>\n      <td>0.210</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-01-07</td>\n      <td>5.600</td>\n      <td>5.716</td>\n      <td>5.580</td>\n      <td>5.648</td>\n      <td>11239500</td>\n      <td>0.072</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2011-01-10</td>\n      <td>5.634</td>\n      <td>5.736</td>\n      <td>5.610</td>\n      <td>5.690</td>\n      <td>6713500</td>\n      <td>0.042</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2011-01-11</td>\n      <td>5.718</td>\n      <td>5.742</td>\n      <td>5.384</td>\n      <td>5.392</td>\n      <td>8551000</td>\n      <td>-0.298</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2011-01-12</td>\n      <td>5.402</td>\n      <td>5.480</td>\n      <td>5.304</td>\n      <td>5.392</td>\n      <td>4822000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2011-01-13</td>\n      <td>5.392</td>\n      <td>5.394</td>\n      <td>5.232</td>\n      <td>5.244</td>\n      <td>3618000</td>\n      <td>-0.148</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2011-01-14</td>\n      <td>5.230</td>\n      <td>5.316</td>\n      <td>5.122</td>\n      <td>5.150</td>\n      <td>5960000</td>\n      <td>-0.094</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Calculate change in stock price\n",
    "tesla_df['change'] = tesla_df['close'].diff()\n",
    "tesla_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d712d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.to_csv('data/tesla_stocks.csv', index=False)"
   ]
  },
  {
   "source": [
    "## (2.4) Upload dataset to SQL Database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.to_sql('stock', engine, if_exists ='replace',method='multi', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('mlenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "801dd5eee37480936b14d219984276aecdbc0fffcaa1c38299e8fde776f1c6c6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}