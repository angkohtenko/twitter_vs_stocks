{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29d489e",
   "metadata": {},
   "source": [
    "# (1) Twitter Data\n",
    "## (1.1) Getting twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6a5765ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from path import Path\n",
    "\n",
    "from twarc import Twarc2, expansions\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f73f8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import bearer_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5b804e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Twarc2(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "42efd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'elonmusk'\n",
    "posts_dict = {\n",
    "    'date':[],\n",
    "    'text':[],\n",
    "    'like_count':[],\n",
    "    'quote_count':[],\n",
    "    'reply_count':[],\n",
    "    'retweet_count':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1bde4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull posts from Twitter and create a dictionary\n",
    "user_timeline = client.timeline(user=user, exclude_replies=True, start_time=datetime.datetime(2017,1,20, 0, 0, 0) )\n",
    "for page in user_timeline:\n",
    "    result = expansions.flatten(page)\n",
    "    for tweet in result:\n",
    "        posts_dict['date'].append(tweet['created_at'])\n",
    "        posts_dict['text'].append(tweet['text'])\n",
    "        posts_dict['like_count'].append(tweet['public_metrics']['like_count'])\n",
    "        posts_dict['quote_count'].append(tweet['public_metrics']['quote_count'])\n",
    "        posts_dict['reply_count'].append(tweet['public_metrics']['reply_count'])\n",
    "        posts_dict['retweet_count'].append(tweet['public_metrics']['retweet_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "159622c3",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(849, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 217
    }
   ],
   "source": [
    "# convert dictionary of posts to dataframe\n",
    "twitter_df = pd.DataFrame.from_dict(posts_dict)\n",
    "twitter_df.head()\n",
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c62e0",
   "metadata": {},
   "source": [
    "## (1.2) Clean the twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "971be6ce",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         date  \\\n",
       "0    2021-07-14T23:35:39.000Z   \n",
       "1    2021-07-14T21:30:25.000Z   \n",
       "2    2021-07-14T02:42:29.000Z   \n",
       "3    2021-07-13T03:05:20.000Z   \n",
       "4    2021-07-13T02:37:57.000Z   \n",
       "..                        ...   \n",
       "844  2020-06-21T07:03:08.000Z   \n",
       "845  2020-06-21T06:19:41.000Z   \n",
       "846  2020-06-21T05:18:44.000Z   \n",
       "847  2020-06-21T00:31:25.000Z   \n",
       "848  2020-06-19T17:06:03.000Z   \n",
       "\n",
       "                                                  text  like_count  \\\n",
       "0    Review of Model S Plaid by Dan Neil\\nhttps://t...       30823   \n",
       "1    Some light reading with lil X https://t.co/MHj...      108772   \n",
       "2    RT @Tesla: You can stream¬†Netflix &amp; YouTub...           0   \n",
       "3    those who attack space\\nmaybe don‚Äôt realize th...      248737   \n",
       "4    Loki is pretty good. Basically, live-action @R...      135505   \n",
       "..                                                 ...         ...   \n",
       "844                                 Mars is my souldog      187197   \n",
       "845  If heat death is the end of the universe, it r...      144469   \n",
       "846  RT @cleantechnica: Exclusive Pro Photos: Tesla...           0   \n",
       "847                 RT @Tesla: https://t.co/26o1bAP14v           0   \n",
       "848  Juneteenth is henceforth considered a US holid...      402800   \n",
       "\n",
       "     quote_count  reply_count  retweet_count  \n",
       "0            195         5457           2702  \n",
       "1            412         5653           4543  \n",
       "2              0            0           2809  \n",
       "3          13371        31288          23041  \n",
       "4           2875         7233           9135  \n",
       "..           ...          ...            ...  \n",
       "844          911         4137          10615  \n",
       "845          896         3533          12618  \n",
       "846            0            0            529  \n",
       "847            0            0           2167  \n",
       "848         2590         5884          31264  \n",
       "\n",
       "[849 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>like_count</th>\n      <th>quote_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-07-14T23:35:39.000Z</td>\n      <td>Review of Model S Plaid by Dan Neil\\nhttps://t...</td>\n      <td>30823</td>\n      <td>195</td>\n      <td>5457</td>\n      <td>2702</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-07-14T21:30:25.000Z</td>\n      <td>Some light reading with lil X https://t.co/MHj...</td>\n      <td>108772</td>\n      <td>412</td>\n      <td>5653</td>\n      <td>4543</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-07-14T02:42:29.000Z</td>\n      <td>RT @Tesla: You can stream¬†Netflix &amp;amp; YouTub...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2809</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-07-13T03:05:20.000Z</td>\n      <td>those who attack space\\nmaybe don‚Äôt realize th...</td>\n      <td>248737</td>\n      <td>13371</td>\n      <td>31288</td>\n      <td>23041</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-07-13T02:37:57.000Z</td>\n      <td>Loki is pretty good. Basically, live-action @R...</td>\n      <td>135505</td>\n      <td>2875</td>\n      <td>7233</td>\n      <td>9135</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>844</th>\n      <td>2020-06-21T07:03:08.000Z</td>\n      <td>Mars is my souldog</td>\n      <td>187197</td>\n      <td>911</td>\n      <td>4137</td>\n      <td>10615</td>\n    </tr>\n    <tr>\n      <th>845</th>\n      <td>2020-06-21T06:19:41.000Z</td>\n      <td>If heat death is the end of the universe, it r...</td>\n      <td>144469</td>\n      <td>896</td>\n      <td>3533</td>\n      <td>12618</td>\n    </tr>\n    <tr>\n      <th>846</th>\n      <td>2020-06-21T05:18:44.000Z</td>\n      <td>RT @cleantechnica: Exclusive Pro Photos: Tesla...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>529</td>\n    </tr>\n    <tr>\n      <th>847</th>\n      <td>2020-06-21T00:31:25.000Z</td>\n      <td>RT @Tesla: https://t.co/26o1bAP14v</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2167</td>\n    </tr>\n    <tr>\n      <th>848</th>\n      <td>2020-06-19T17:06:03.000Z</td>\n      <td>Juneteenth is henceforth considered a US holid...</td>\n      <td>402800</td>\n      <td>2590</td>\n      <td>5884</td>\n      <td>31264</td>\n    </tr>\n  </tbody>\n</table>\n<p>849 rows √ó 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 218
    }
   ],
   "source": [
    "# Drop the NaNs\n",
    "twitter_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "863da221",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "date             object\n",
       "text             object\n",
       "like_count        int64\n",
       "quote_count       int64\n",
       "reply_count       int64\n",
       "retweet_count     int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 219
    }
   ],
   "source": [
    "# Determine data types for each column\n",
    "twitter_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "aba95493",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(849, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 220
    }
   ],
   "source": [
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "378beb62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date                                               text  like_count  \\\n",
       "0 2021-07-14  Review of Model S Plaid by Dan Neil\\nhttps://t...       30823   \n",
       "1 2021-07-14  Some light reading with lil X https://t.co/MHj...      108772   \n",
       "2 2021-07-14  RT @Tesla: You can stream¬†Netflix &amp; YouTub...           0   \n",
       "3 2021-07-13  those who attack space\\nmaybe don‚Äôt realize th...      248737   \n",
       "4 2021-07-13  Loki is pretty good. Basically, live-action @R...      135505   \n",
       "\n",
       "   quote_count  reply_count  retweet_count  \n",
       "0          195         5457           2702  \n",
       "1          412         5653           4543  \n",
       "2            0            0           2809  \n",
       "3        13371        31288          23041  \n",
       "4         2875         7233           9135  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>like_count</th>\n      <th>quote_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-07-14</td>\n      <td>Review of Model S Plaid by Dan Neil\\nhttps://t...</td>\n      <td>30823</td>\n      <td>195</td>\n      <td>5457</td>\n      <td>2702</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-07-14</td>\n      <td>Some light reading with lil X https://t.co/MHj...</td>\n      <td>108772</td>\n      <td>412</td>\n      <td>5653</td>\n      <td>4543</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-07-14</td>\n      <td>RT @Tesla: You can stream¬†Netflix &amp;amp; YouTub...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2809</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-07-13</td>\n      <td>those who attack space\\nmaybe don‚Äôt realize th...</td>\n      <td>248737</td>\n      <td>13371</td>\n      <td>31288</td>\n      <td>23041</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-07-13</td>\n      <td>Loki is pretty good. Basically, live-action @R...</td>\n      <td>135505</td>\n      <td>2875</td>\n      <td>7233</td>\n      <td>9135</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 221
    }
   ],
   "source": [
    "# Let's convert the date.\n",
    "twitter_df['date'] = pd.to_datetime(twitter_df['date']).dt.date.astype('datetime64')\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b731df31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "\n",
    "def f(x):\n",
    "     return Series(dict(like_count = x['like_count'].sum(),\n",
    "                        quote_count = x['quote_count'].sum(),\n",
    "                        reply_count = x['reply_count'].sum(),\n",
    "                        retweet_count = x['retweet_count'].sum(),\n",
    "                        text = \"{%s}\" % ', '.join(x['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "2d661c8a",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date  like_count  quote_count  reply_count  retweet_count  \\\n",
       "0 2020-06-19      402800         2590         5884          31264   \n",
       "1 2020-06-21      735629         4879        17989          57388   \n",
       "2 2020-06-22      133516          892         5246           5438   \n",
       "3 2020-06-25      259296         1039         4758          10802   \n",
       "4 2020-06-26     2248367        24436        32923         300062   \n",
       "\n",
       "                                                text  \n",
       "0  {Juneteenth is henceforth considered a US holi...  \n",
       "1  {2019 seems so quaint &amp; long ago https://t...  \n",
       "2  {Tentative date for Tesla Shareholder Meeting ...  \n",
       "3  {RT @GerberKawasaki: First thoughts driving my...  \n",
       "4  {.@JeffBezos is a copy üêà haha https://t.co/plR...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>like_count</th>\n      <th>quote_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-06-19</td>\n      <td>402800</td>\n      <td>2590</td>\n      <td>5884</td>\n      <td>31264</td>\n      <td>{Juneteenth is henceforth considered a US holi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-06-21</td>\n      <td>735629</td>\n      <td>4879</td>\n      <td>17989</td>\n      <td>57388</td>\n      <td>{2019 seems so quaint &amp;amp; long ago https://t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-06-22</td>\n      <td>133516</td>\n      <td>892</td>\n      <td>5246</td>\n      <td>5438</td>\n      <td>{Tentative date for Tesla Shareholder Meeting ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-06-25</td>\n      <td>259296</td>\n      <td>1039</td>\n      <td>4758</td>\n      <td>10802</td>\n      <td>{RT @GerberKawasaki: First thoughts driving my...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-06-26</td>\n      <td>2248367</td>\n      <td>24436</td>\n      <td>32923</td>\n      <td>300062</td>\n      <td>{.@JeffBezos is a copy üêà haha https://t.co/plR...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 223
    }
   ],
   "source": [
    "twitter_df = twitter_df.groupby('date').apply(f).reset_index()\n",
    "twitter_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad7518",
   "metadata": {},
   "source": [
    "## (1.3) Preprocessing the Twitter data\n",
    "\n",
    "**Preprocess the data by making it all lowercase. Remove a reasonable set of stopwords from the dataset and tokenize. Then, report the 10 most common words and their count. We need to iterate this process, adding some stop words as we understand the structure of the data. Justify additional stop words we've added.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a0fd768a",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ziza/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date  like_count  quote_count  reply_count  retweet_count  \\\n",
       "0 2020-06-19      402800         2590         5884          31264   \n",
       "1 2020-06-21      735629         4879        17989          57388   \n",
       "2 2020-06-22      133516          892         5246           5438   \n",
       "3 2020-06-25      259296         1039         4758          10802   \n",
       "4 2020-06-26     2248367        24436        32923         300062   \n",
       "\n",
       "                                                text  \\\n",
       "0  {Juneteenth is henceforth considered a US holi...   \n",
       "1  {2019 seems so quaint &amp; long ago https://t...   \n",
       "2  {Tentative date for Tesla Shareholder Meeting ...   \n",
       "3  {RT @GerberKawasaki: First thoughts driving my...   \n",
       "4  {.@JeffBezos is a copy üêà haha https://t.co/plR...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  {juneteenth is henceforth considered a us holi...   \n",
       "1  {2019 seems so quaint &amp; long ago that is o...   \n",
       "2  {tentative date for tesla shareholder meeting ...   \n",
       "3  {rt @gerberkawasaki: first thoughts driving my...   \n",
       "4  {.@jeffbezos is a copy üêà haha who controls the...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [juneteenth, henceforth, considered, holiday, ...  \n",
       "1  [seems, quaint, long, ago, purpose, tesla, bio...  \n",
       "2  [tentative, date, tesla, shareholder, meeting,...  \n",
       "3  [gerberkawasaki, first, thoughts, driving, new...  \n",
       "4  [jeffbezos, copy, controls, memes, controls, u...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>like_count</th>\n      <th>quote_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n      <th>text</th>\n      <th>preprocessed_text</th>\n      <th>tokenized_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-06-19</td>\n      <td>402800</td>\n      <td>2590</td>\n      <td>5884</td>\n      <td>31264</td>\n      <td>{Juneteenth is henceforth considered a US holi...</td>\n      <td>{juneteenth is henceforth considered a us holi...</td>\n      <td>[juneteenth, henceforth, considered, holiday, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-06-21</td>\n      <td>735629</td>\n      <td>4879</td>\n      <td>17989</td>\n      <td>57388</td>\n      <td>{2019 seems so quaint &amp;amp; long ago https://t...</td>\n      <td>{2019 seems so quaint &amp;amp; long ago that is o...</td>\n      <td>[seems, quaint, long, ago, purpose, tesla, bio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-06-22</td>\n      <td>133516</td>\n      <td>892</td>\n      <td>5246</td>\n      <td>5438</td>\n      <td>{Tentative date for Tesla Shareholder Meeting ...</td>\n      <td>{tentative date for tesla shareholder meeting ...</td>\n      <td>[tentative, date, tesla, shareholder, meeting,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-06-25</td>\n      <td>259296</td>\n      <td>1039</td>\n      <td>4758</td>\n      <td>10802</td>\n      <td>{RT @GerberKawasaki: First thoughts driving my...</td>\n      <td>{rt @gerberkawasaki: first thoughts driving my...</td>\n      <td>[gerberkawasaki, first, thoughts, driving, new...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-06-26</td>\n      <td>2248367</td>\n      <td>24436</td>\n      <td>32923</td>\n      <td>300062</td>\n      <td>{.@JeffBezos is a copy üêà haha https://t.co/plR...</td>\n      <td>{.@jeffbezos is a copy üêà haha who controls the...</td>\n      <td>[jeffbezos, copy, controls, memes, controls, u...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 224
    }
   ],
   "source": [
    "# Data Pre-processing and make the tweets all lowercase and remove stopwords.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from datetime import datetime\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "\n",
    "# lower the tweets\n",
    "twitter_df['preprocessed_text'] = twitter_df['text'].str.lower()\n",
    "\n",
    "\n",
    "# remove apostrophe from words and curly braces\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"('[a-z])\\s\", \"\", row) for row in twitter_df['preprocessed_text']]\n",
    "                                      \n",
    "# filter out URLs\n",
    "url_re = '(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'  \n",
    "\n",
    "twitter_df['preprocessed_text'] = twitter_df['preprocessed_text'].apply(lambda row: ' '.join([word for word in row.split() if (not re.match(url_re, word))]))\n",
    "\n",
    "# tokenize the tweets\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z]\\w+\\'?\\w*')\n",
    "twitter_df['tokenized_text'] = twitter_df['preprocessed_text'].apply(lambda row: tokenizer.tokenize(row))\n",
    "\n",
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# apply stemming\n",
    "twitter_df['preprocessed_text'] = [porter.stem(row) for row in twitter_df['preprocessed_text']]   \n",
    "\n",
    "# filter out stop words\n",
    "en_stop_words = nltk.corpus.stopwords.words('english')\n",
    "additional_stop_words =['amp', 'rt', 'th','co', 're', 've', 'kim', 'daca', 'us', 'it', 'th', 'you', 'haha', 'st', 'et', 'so', 'iii', 'also', 've', 'la', 're', 'the', 'https', 'wow', 'actually', 'due', 'ft', 'pcr', 'via', 'am', 'gt', 'com', 'since', 'in', 'me', 'and', 'btw', 'yesterday', 'ii', 'inu', 'on', 'http', 'to', 'vs', 'rd', 'ur', 'of', 'bs', 'km', 'est', 'em', 'lz', 'kms', 'aft', 'nd',  'here‚Äôs', 're', 'mqxfakpzf' 'mph', 'ht', 'etc', 'dm']\n",
    "en_stop_words.extend(additional_stop_words)\n",
    "\n",
    "twitter_df['tokenized_text'] = twitter_df['tokenized_text'].apply(lambda row: [word for word in row if (not word in en_stop_words)])\n",
    "\n",
    "df_tweets_clean = twitter_df.copy()\n",
    "df_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "caba4f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date                                               text  \\\n",
       "0 2020-06-19  {Juneteenth is henceforth considered a US holi...   \n",
       "1 2020-06-21  {2019 seems so quaint &amp; long ago https://t...   \n",
       "2 2020-06-22  {Tentative date for Tesla Shareholder Meeting ...   \n",
       "3 2020-06-25  {RT @GerberKawasaki: First thoughts driving my...   \n",
       "4 2020-06-26  {.@JeffBezos is a copy üêà haha https://t.co/plR...   \n",
       "5 2020-06-28  {Btw, Tesla actually receives *least* subsidie...   \n",
       "6 2020-06-30  {Your GPS just got slightly better https://t.c...   \n",
       "7 2020-07-01  {Tesla Impact Report (repost). We do everythin...   \n",
       "8 2020-07-02  {Thanks Tesla owners &amp; investors! Love you...   \n",
       "9 2020-07-04  {Please take a moment to report accounts clear...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  {juneteenth is henceforth considered a us holi...   \n",
       "1  {2019 seems so quaint &amp; long ago that is o...   \n",
       "2  {tentative date for tesla shareholder meeting ...   \n",
       "3  {rt @gerberkawasaki: first thoughts driving my...   \n",
       "4  {.@jeffbezos is a copy üêà haha who controls the...   \n",
       "5  {btw, tesla actually receives *least* subsidie...   \n",
       "6  {your gps just got slightly better rt @spacex:...   \n",
       "7  {tesla impact report (repost). we do everythin...   \n",
       "8  {thanks tesla owners &amp; investors! love you...   \n",
       "9  {please take a moment to report accounts clear...   \n",
       "\n",
       "                                      tokenized_text  like_count  quote_count  \\\n",
       "0  [juneteenth, henceforth, considered, holiday, ...      402800         2590   \n",
       "1  [seems, quaint, long, ago, purpose, tesla, bio...      735629         4879   \n",
       "2  [tentative, date, tesla, shareholder, meeting,...      133516          892   \n",
       "3  [gerberkawasaki, first, thoughts, driving, new...      259296         1039   \n",
       "4  [jeffbezos, copy, controls, memes, controls, u...     2248367        24436   \n",
       "5  [tesla, receives, least, subsidies, automaker,...      549854         5325   \n",
       "6  [gps, got, slightly, better, spacex, falcon, f...      156800          688   \n",
       "7  [tesla, impact, report, repost, everything, hu...       26879          208   \n",
       "8  [thanks, tesla, owners, investors, love, work,...      601022        11573   \n",
       "9  [please, take, moment, report, accounts, clear...      378083         2674   \n",
       "\n",
       "   reply_count  retweet_count  \n",
       "0         5884          31264  \n",
       "1        17989          57388  \n",
       "2         5246           5438  \n",
       "3         4758          10802  \n",
       "4        32923         300062  \n",
       "5        10656          55443  \n",
       "6         2610          21575  \n",
       "7         1657           2530  \n",
       "8        31284          39499  \n",
       "9        15608          32529  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>preprocessed_text</th>\n      <th>tokenized_text</th>\n      <th>like_count</th>\n      <th>quote_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-06-19</td>\n      <td>{Juneteenth is henceforth considered a US holi...</td>\n      <td>{juneteenth is henceforth considered a us holi...</td>\n      <td>[juneteenth, henceforth, considered, holiday, ...</td>\n      <td>402800</td>\n      <td>2590</td>\n      <td>5884</td>\n      <td>31264</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-06-21</td>\n      <td>{2019 seems so quaint &amp;amp; long ago https://t...</td>\n      <td>{2019 seems so quaint &amp;amp; long ago that is o...</td>\n      <td>[seems, quaint, long, ago, purpose, tesla, bio...</td>\n      <td>735629</td>\n      <td>4879</td>\n      <td>17989</td>\n      <td>57388</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-06-22</td>\n      <td>{Tentative date for Tesla Shareholder Meeting ...</td>\n      <td>{tentative date for tesla shareholder meeting ...</td>\n      <td>[tentative, date, tesla, shareholder, meeting,...</td>\n      <td>133516</td>\n      <td>892</td>\n      <td>5246</td>\n      <td>5438</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-06-25</td>\n      <td>{RT @GerberKawasaki: First thoughts driving my...</td>\n      <td>{rt @gerberkawasaki: first thoughts driving my...</td>\n      <td>[gerberkawasaki, first, thoughts, driving, new...</td>\n      <td>259296</td>\n      <td>1039</td>\n      <td>4758</td>\n      <td>10802</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-06-26</td>\n      <td>{.@JeffBezos is a copy üêà haha https://t.co/plR...</td>\n      <td>{.@jeffbezos is a copy üêà haha who controls the...</td>\n      <td>[jeffbezos, copy, controls, memes, controls, u...</td>\n      <td>2248367</td>\n      <td>24436</td>\n      <td>32923</td>\n      <td>300062</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2020-06-28</td>\n      <td>{Btw, Tesla actually receives *least* subsidie...</td>\n      <td>{btw, tesla actually receives *least* subsidie...</td>\n      <td>[tesla, receives, least, subsidies, automaker,...</td>\n      <td>549854</td>\n      <td>5325</td>\n      <td>10656</td>\n      <td>55443</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2020-06-30</td>\n      <td>{Your GPS just got slightly better https://t.c...</td>\n      <td>{your gps just got slightly better rt @spacex:...</td>\n      <td>[gps, got, slightly, better, spacex, falcon, f...</td>\n      <td>156800</td>\n      <td>688</td>\n      <td>2610</td>\n      <td>21575</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2020-07-01</td>\n      <td>{Tesla Impact Report (repost). We do everythin...</td>\n      <td>{tesla impact report (repost). we do everythin...</td>\n      <td>[tesla, impact, report, repost, everything, hu...</td>\n      <td>26879</td>\n      <td>208</td>\n      <td>1657</td>\n      <td>2530</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2020-07-02</td>\n      <td>{Thanks Tesla owners &amp;amp; investors! Love you...</td>\n      <td>{thanks tesla owners &amp;amp; investors! love you...</td>\n      <td>[thanks, tesla, owners, investors, love, work,...</td>\n      <td>601022</td>\n      <td>11573</td>\n      <td>31284</td>\n      <td>39499</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2020-07-04</td>\n      <td>{Please take a moment to report accounts clear...</td>\n      <td>{please take a moment to report accounts clear...</td>\n      <td>[please, take, moment, report, accounts, clear...</td>\n      <td>378083</td>\n      <td>2674</td>\n      <td>15608</td>\n      <td>32529</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 225
    }
   ],
   "source": [
    "df_tweets_clean = df_tweets_clean[['date', 'text', 'preprocessed_text', 'tokenized_text', 'like_count', 'quote_count', 'reply_count', 'retweet_count']]\n",
    "df_tweets_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date                                               text  \\\n",
       "0 2020-06-19  {Juneteenth is henceforth considered a US holi...   \n",
       "1 2020-06-21  {2019 seems so quaint &amp; long ago https://t...   \n",
       "2 2020-06-22  {Tentative date for Tesla Shareholder Meeting ...   \n",
       "3 2020-06-25  {RT @GerberKawasaki: First thoughts driving my...   \n",
       "4 2020-06-26  {.@JeffBezos is a copy üêà haha https://t.co/plR...   \n",
       "\n",
       "                                      tokenized_text  like_count  quote_count  \\\n",
       "0  [juneteenth, henceforth, considered, holiday, ...      402800         2590   \n",
       "1  [seems, quaint, long, ago, purpose, tesla, bio...      735629         4879   \n",
       "2  [tentative, date, tesla, shareholder, meeting,...      133516          892   \n",
       "3  [gerberkawasaki, first, thoughts, driving, new...      259296         1039   \n",
       "4  [jeffbezos, copy, controls, memes, controls, u...     2248367        24436   \n",
       "\n",
       "   reply_count  retweet_count  \n",
       "0         5884          31264  \n",
       "1        17989          57388  \n",
       "2         5246           5438  \n",
       "3         4758          10802  \n",
       "4        32923         300062  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>tokenized_text</th>\n      <th>like_count</th>\n      <th>quote_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-06-19</td>\n      <td>{Juneteenth is henceforth considered a US holi...</td>\n      <td>[juneteenth, henceforth, considered, holiday, ...</td>\n      <td>402800</td>\n      <td>2590</td>\n      <td>5884</td>\n      <td>31264</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-06-21</td>\n      <td>{2019 seems so quaint &amp;amp; long ago https://t...</td>\n      <td>[seems, quaint, long, ago, purpose, tesla, bio...</td>\n      <td>735629</td>\n      <td>4879</td>\n      <td>17989</td>\n      <td>57388</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-06-22</td>\n      <td>{Tentative date for Tesla Shareholder Meeting ...</td>\n      <td>[tentative, date, tesla, shareholder, meeting,...</td>\n      <td>133516</td>\n      <td>892</td>\n      <td>5246</td>\n      <td>5438</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-06-25</td>\n      <td>{RT @GerberKawasaki: First thoughts driving my...</td>\n      <td>[gerberkawasaki, first, thoughts, driving, new...</td>\n      <td>259296</td>\n      <td>1039</td>\n      <td>4758</td>\n      <td>10802</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-06-26</td>\n      <td>{.@JeffBezos is a copy üêà haha https://t.co/plR...</td>\n      <td>[jeffbezos, copy, controls, memes, controls, u...</td>\n      <td>2248367</td>\n      <td>24436</td>\n      <td>32923</td>\n      <td>300062</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 226
    }
   ],
   "source": [
    "df_tweets_clean = df_tweets_clean.drop(columns=['preprocessed_text'])\n",
    "df_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6338deb5",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('spacex', 170),\n",
       " ('tesla', 114),\n",
       " ('launch', 56),\n",
       " ('dragon', 55),\n",
       " ('falcon', 53),\n",
       " ('first', 44),\n",
       " ('nasa', 36),\n",
       " ('crew', 35),\n",
       " ('space_station', 30),\n",
       " ('model', 29)]"
      ]
     },
     "metadata": {},
     "execution_count": 228
    }
   ],
   "source": [
    "# the most common words and their count\n",
    "def get_most_freq_words(str, n=None):\n",
    "    vect = CountVectorizer().fit(str)\n",
    "    bag_of_words = vect.transform(str)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
    "    return freq[:n]\n",
    "  \n",
    "get_most_freq_words([ word for tweet in df_tweets_clean.tokenized_text for word in tweet],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "effaa3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.to_csv('data/tweets_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf788124",
   "metadata": {},
   "source": [
    "# (2 ) Stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c8153",
   "metadata": {},
   "source": [
    "## (2.1) Getting the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5ee54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from yahoo_fin.stock_info import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "725dce38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.508000</td>\n",
       "      <td>4.778000</td>\n",
       "      <td>4.778000</td>\n",
       "      <td>93831500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>5.158000</td>\n",
       "      <td>6.084000</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>4.766000</td>\n",
       "      <td>4.766000</td>\n",
       "      <td>85935500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.184000</td>\n",
       "      <td>4.054000</td>\n",
       "      <td>4.392000</td>\n",
       "      <td>4.392000</td>\n",
       "      <td>41094000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>3.742000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>25699000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.166000</td>\n",
       "      <td>3.222000</td>\n",
       "      <td>3.222000</td>\n",
       "      <td>34334500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>628.369995</td>\n",
       "      <td>654.429993</td>\n",
       "      <td>620.460022</td>\n",
       "      <td>652.809998</td>\n",
       "      <td>652.809998</td>\n",
       "      <td>22773300</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>2021-07-09</td>\n",
       "      <td>653.179993</td>\n",
       "      <td>658.909973</td>\n",
       "      <td>644.690002</td>\n",
       "      <td>656.950012</td>\n",
       "      <td>656.950012</td>\n",
       "      <td>18118500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>662.200012</td>\n",
       "      <td>687.239990</td>\n",
       "      <td>662.159973</td>\n",
       "      <td>685.700012</td>\n",
       "      <td>685.700012</td>\n",
       "      <td>25927000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>686.320007</td>\n",
       "      <td>693.280029</td>\n",
       "      <td>666.299988</td>\n",
       "      <td>668.539978</td>\n",
       "      <td>668.539978</td>\n",
       "      <td>20847500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>670.750000</td>\n",
       "      <td>678.609985</td>\n",
       "      <td>652.840027</td>\n",
       "      <td>653.380005</td>\n",
       "      <td>653.380005</td>\n",
       "      <td>21612700</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2780 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date        open        high         low       close    adjclose  \\\n",
       "0    2010-06-29    3.800000    5.000000    3.508000    4.778000    4.778000   \n",
       "1    2010-06-30    5.158000    6.084000    4.660000    4.766000    4.766000   \n",
       "2    2010-07-01    5.000000    5.184000    4.054000    4.392000    4.392000   \n",
       "3    2010-07-02    4.600000    4.620000    3.742000    3.840000    3.840000   \n",
       "4    2010-07-06    4.000000    4.000000    3.166000    3.222000    3.222000   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "2775 2021-07-08  628.369995  654.429993  620.460022  652.809998  652.809998   \n",
       "2776 2021-07-09  653.179993  658.909973  644.690002  656.950012  656.950012   \n",
       "2777 2021-07-12  662.200012  687.239990  662.159973  685.700012  685.700012   \n",
       "2778 2021-07-13  686.320007  693.280029  666.299988  668.539978  668.539978   \n",
       "2779 2021-07-14  670.750000  678.609985  652.840027  653.380005  653.380005   \n",
       "\n",
       "        volume ticker  \n",
       "0     93831500   TSLA  \n",
       "1     85935500   TSLA  \n",
       "2     41094000   TSLA  \n",
       "3     25699000   TSLA  \n",
       "4     34334500   TSLA  \n",
       "...        ...    ...  \n",
       "2775  22773300   TSLA  \n",
       "2776  18118500   TSLA  \n",
       "2777  25927000   TSLA  \n",
       "2778  20847500   TSLA  \n",
       "2779  21612700   TSLA  \n",
       "\n",
       "[2780 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# historical daily data from Yahoo finance\n",
    "tesla_df = get_data(\"tsla\", start_date = None, end_date = None, index_as_date = False, interval=\"1d\")\n",
    "tesla_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e57be6",
   "metadata": {},
   "source": [
    "## (2.2) Clean the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72eba53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>3.800</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.508</td>\n",
       "      <td>4.778</td>\n",
       "      <td>93831500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>5.158</td>\n",
       "      <td>6.084</td>\n",
       "      <td>4.660</td>\n",
       "      <td>4.766</td>\n",
       "      <td>85935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.184</td>\n",
       "      <td>4.054</td>\n",
       "      <td>4.392</td>\n",
       "      <td>41094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>4.600</td>\n",
       "      <td>4.620</td>\n",
       "      <td>3.742</td>\n",
       "      <td>3.840</td>\n",
       "      <td>25699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.166</td>\n",
       "      <td>3.222</td>\n",
       "      <td>34334500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close    volume\n",
       "0 2010-06-29  3.800  5.000  3.508  4.778  93831500\n",
       "1 2010-06-30  5.158  6.084  4.660  4.766  85935500\n",
       "2 2010-07-01  5.000  5.184  4.054  4.392  41094000\n",
       "3 2010-07-02  4.600  4.620  3.742  3.840  25699000\n",
       "4 2010-07-06  4.000  4.000  3.166  3.222  34334500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop adjclose column\n",
    "tesla_df = tesla_df.drop(columns=[\"adjclose\", \"ticker\"])\n",
    "tesla_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fff742f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      datetime64[ns]\n",
       "open             float64\n",
       "high             float64\n",
       "low              float64\n",
       "close            float64\n",
       "volume             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine data types for each column\n",
    "tesla_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc19c0",
   "metadata": {},
   "source": [
    "## (2.3) Preprocessing the Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f772a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>3.800</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.508</td>\n",
       "      <td>4.778</td>\n",
       "      <td>93831500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>5.158</td>\n",
       "      <td>6.084</td>\n",
       "      <td>4.660</td>\n",
       "      <td>4.766</td>\n",
       "      <td>85935500</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.184</td>\n",
       "      <td>4.054</td>\n",
       "      <td>4.392</td>\n",
       "      <td>41094000</td>\n",
       "      <td>-0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>4.600</td>\n",
       "      <td>4.620</td>\n",
       "      <td>3.742</td>\n",
       "      <td>3.840</td>\n",
       "      <td>25699000</td>\n",
       "      <td>-0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.166</td>\n",
       "      <td>3.222</td>\n",
       "      <td>34334500</td>\n",
       "      <td>-0.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-07-07</td>\n",
       "      <td>3.280</td>\n",
       "      <td>3.326</td>\n",
       "      <td>2.996</td>\n",
       "      <td>3.160</td>\n",
       "      <td>34608500</td>\n",
       "      <td>-0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-07-08</td>\n",
       "      <td>3.228</td>\n",
       "      <td>3.504</td>\n",
       "      <td>3.114</td>\n",
       "      <td>3.492</td>\n",
       "      <td>38557000</td>\n",
       "      <td>0.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-07-09</td>\n",
       "      <td>3.516</td>\n",
       "      <td>3.580</td>\n",
       "      <td>3.310</td>\n",
       "      <td>3.480</td>\n",
       "      <td>20253000</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-07-12</td>\n",
       "      <td>3.590</td>\n",
       "      <td>3.614</td>\n",
       "      <td>3.400</td>\n",
       "      <td>3.410</td>\n",
       "      <td>11012500</td>\n",
       "      <td>-0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-07-13</td>\n",
       "      <td>3.478</td>\n",
       "      <td>3.728</td>\n",
       "      <td>3.380</td>\n",
       "      <td>3.628</td>\n",
       "      <td>13400500</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close    volume  change\n",
       "0 2010-06-29  3.800  5.000  3.508  4.778  93831500     NaN\n",
       "1 2010-06-30  5.158  6.084  4.660  4.766  85935500  -0.012\n",
       "2 2010-07-01  5.000  5.184  4.054  4.392  41094000  -0.374\n",
       "3 2010-07-02  4.600  4.620  3.742  3.840  25699000  -0.552\n",
       "4 2010-07-06  4.000  4.000  3.166  3.222  34334500  -0.618\n",
       "5 2010-07-07  3.280  3.326  2.996  3.160  34608500  -0.062\n",
       "6 2010-07-08  3.228  3.504  3.114  3.492  38557000   0.332\n",
       "7 2010-07-09  3.516  3.580  3.310  3.480  20253000  -0.012\n",
       "8 2010-07-12  3.590  3.614  3.400  3.410  11012500  -0.070\n",
       "9 2010-07-13  3.478  3.728  3.380  3.628  13400500   0.218"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate change in stock price\n",
    "tesla_df['change'] = tesla_df['close'].diff()\n",
    "tesla_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d712d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.to_csv('data/tesla_stocks', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}