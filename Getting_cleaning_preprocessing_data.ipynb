{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29d489e",
   "metadata": {},
   "source": [
    "# (1) Twitter Data\n",
    "## (1.1) Getting Twitter data 2021 from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5765ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from path import Path\n",
    "from twarc import Twarc2, expansions\n",
    "import json\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73f8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import bearer_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b804e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Twarc2(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42efd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'elonmusk'\n",
    "posts_dict = {\n",
    "    'date':[],\n",
    "    'text':[],\n",
    "    'like_count':[],\n",
    "    'reply_count':[],\n",
    "    'retweet_count':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bde4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull posts from Twitter and create a dictionary\n",
    "user_timeline = client.timeline(user=user, exclude_replies=True, start_time=datetime.datetime(2021,1,1, 0, 0, 0) )\n",
    "for page in user_timeline:\n",
    "    result = expansions.flatten(page)\n",
    "    for tweet in result:\n",
    "        posts_dict['date'].append(tweet['created_at'])\n",
    "        posts_dict['text'].append(tweet['text'])\n",
    "        posts_dict['like_count'].append(tweet['public_metrics']['like_count'])\n",
    "        posts_dict['reply_count'].append(tweet['public_metrics']['reply_count'])\n",
    "        posts_dict['retweet_count'].append(tweet['public_metrics']['retweet_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159622c3",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       date  \\\n",
       "0  2021-07-14T23:35:39.000Z   \n",
       "1  2021-07-14T21:30:25.000Z   \n",
       "2  2021-07-14T02:42:29.000Z   \n",
       "3  2021-07-13T03:05:20.000Z   \n",
       "4  2021-07-13T02:37:57.000Z   \n",
       "\n",
       "                                                text  like_count  reply_count  \\\n",
       "0  Review of Model S Plaid by Dan Neil\\nhttps://t...       35736         8979   \n",
       "1  Some light reading with lil X https://t.co/MHj...      123524         6946   \n",
       "2  RT @Tesla: You can stream¬†Netflix &amp; YouTub...           0            0   \n",
       "3  those who attack space\\nmaybe don‚Äôt realize th...      256947        32331   \n",
       "4  Loki is pretty good. Basically, live-action @R...      138710         7435   \n",
       "\n",
       "   retweet_count  \n",
       "0           3219  \n",
       "1           5048  \n",
       "2           2943  \n",
       "3          23730  \n",
       "4           9350  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-07-14T23:35:39.000Z</td>\n      <td>Review of Model S Plaid by Dan Neil\\nhttps://t...</td>\n      <td>35736</td>\n      <td>8979</td>\n      <td>3219</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-07-14T21:30:25.000Z</td>\n      <td>Some light reading with lil X https://t.co/MHj...</td>\n      <td>123524</td>\n      <td>6946</td>\n      <td>5048</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-07-14T02:42:29.000Z</td>\n      <td>RT @Tesla: You can stream¬†Netflix &amp;amp; YouTub...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2943</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-07-13T03:05:20.000Z</td>\n      <td>those who attack space\\nmaybe don‚Äôt realize th...</td>\n      <td>256947</td>\n      <td>32331</td>\n      <td>23730</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-07-13T02:37:57.000Z</td>\n      <td>Loki is pretty good. Basically, live-action @R...</td>\n      <td>138710</td>\n      <td>7435</td>\n      <td>9350</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# convert dictionary of posts to dataframe\n",
    "twitter_2021 = pd.DataFrame.from_dict(posts_dict)\n",
    "twitter_2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          date                                               text  like_count  \\\n",
       "429 2021-01-07  This is called the domino effect https://t.co/...      366578   \n",
       "430 2021-01-04  Because of the large footprint, it may seem fl...       57856   \n",
       "431 2021-01-04  Snow falling on Giga Berlin https://t.co/eTXMt...      148431   \n",
       "432 2021-01-02  So proud of the Tesla team for achieving this ...      109830   \n",
       "433 2021-01-02  RT @Tesla: In 2020, we produced and delivered ...           0   \n",
       "\n",
       "     reply_count  retweet_count  \n",
       "429         4500          37549  \n",
       "430         1386           1073  \n",
       "431         3644           6876  \n",
       "432         4150           6236  \n",
       "433            0           6266  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>429</th>\n      <td>2021-01-07</td>\n      <td>This is called the domino effect https://t.co/...</td>\n      <td>366578</td>\n      <td>4500</td>\n      <td>37549</td>\n    </tr>\n    <tr>\n      <th>430</th>\n      <td>2021-01-04</td>\n      <td>Because of the large footprint, it may seem fl...</td>\n      <td>57856</td>\n      <td>1386</td>\n      <td>1073</td>\n    </tr>\n    <tr>\n      <th>431</th>\n      <td>2021-01-04</td>\n      <td>Snow falling on Giga Berlin https://t.co/eTXMt...</td>\n      <td>148431</td>\n      <td>3644</td>\n      <td>6876</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>2021-01-02</td>\n      <td>So proud of the Tesla team for achieving this ...</td>\n      <td>109830</td>\n      <td>4150</td>\n      <td>6236</td>\n    </tr>\n    <tr>\n      <th>433</th>\n      <td>2021-01-02</td>\n      <td>RT @Tesla: In 2020, we produced and delivered ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6266</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "twitter_2021['date'] = pd.to_datetime(twitter_2021['date']).dt.date.astype('datetime64')\n",
    "twitter_2021.tail()"
   ]
  },
  {
   "source": [
    "## (1.2) Getting Twitter data 2011 - 2020 from archive"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0                   id      conversation_id    created_at  \\\n",
       "0           0  1343644462036086785  1343320495127633920  1.609185e+12   \n",
       "1           1  1343619610617077760  1343386617294295040  1.609179e+12   \n",
       "2           2  1343608616960491521  1343576442722893825  1.609176e+12   \n",
       "3           3  1343608530998153222  1343320495127633920  1.609176e+12   \n",
       "4           4  1343431408052662273  1343043963096326147  1.609134e+12   \n",
       "\n",
       "                  date  timezone  place  \\\n",
       "0  2020-12-28 19:46:18         0    NaN   \n",
       "1  2020-12-28 18:07:33         0    NaN   \n",
       "2  2020-12-28 17:23:51         0    NaN   \n",
       "3  2020-12-28 17:23:31         0    NaN   \n",
       "4  2020-12-28 05:39:42         0    NaN   \n",
       "\n",
       "                                               tweet language hashtags  ...  \\\n",
       "0  Entertainment will be critical when cars drive...       en       []  ...   \n",
       "1  @kimpaquette Just meeting with Larry Ellison t...       en       []  ...   \n",
       "2                        @richierichhhhh_ Absolutely       en       []  ...   \n",
       "3  What should Tesla do with in-car gaming in an ...       en       []  ...   \n",
       "4                          @PPathole @WSJ Absolutely       en       []  ...   \n",
       "\n",
       "  geo  source  user_rt_id user_rt retweet_id  \\\n",
       "0 NaN     NaN         NaN     NaN        NaN   \n",
       "1 NaN     NaN         NaN     NaN        NaN   \n",
       "2 NaN     NaN         NaN     NaN        NaN   \n",
       "3 NaN     NaN         NaN     NaN        NaN   \n",
       "4 NaN     NaN         NaN     NaN        NaN   \n",
       "\n",
       "                                            reply_to  retweet_date translate  \\\n",
       "0                                                 []           NaN       NaN   \n",
       "1  [{'screen_name': 'kimpaquette', 'name': 'Kim P...           NaN       NaN   \n",
       "2  [{'screen_name': 'richierichhhhh_', 'name': 'R...           NaN       NaN   \n",
       "3                                                 []           NaN       NaN   \n",
       "4  [{'screen_name': 'PPathole', 'name': 'Pranay P...           NaN       NaN   \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        NaN  \n",
       "4       NaN        NaN  \n",
       "\n",
       "[5 rows x 39 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>conversation_id</th>\n      <th>created_at</th>\n      <th>date</th>\n      <th>timezone</th>\n      <th>place</th>\n      <th>tweet</th>\n      <th>language</th>\n      <th>hashtags</th>\n      <th>...</th>\n      <th>geo</th>\n      <th>source</th>\n      <th>user_rt_id</th>\n      <th>user_rt</th>\n      <th>retweet_id</th>\n      <th>reply_to</th>\n      <th>retweet_date</th>\n      <th>translate</th>\n      <th>trans_src</th>\n      <th>trans_dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1343644462036086785</td>\n      <td>1343320495127633920</td>\n      <td>1.609185e+12</td>\n      <td>2020-12-28 19:46:18</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>Entertainment will be critical when cars drive...</td>\n      <td>en</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1343619610617077760</td>\n      <td>1343386617294295040</td>\n      <td>1.609179e+12</td>\n      <td>2020-12-28 18:07:33</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>@kimpaquette Just meeting with Larry Ellison t...</td>\n      <td>en</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[{'screen_name': 'kimpaquette', 'name': 'Kim P...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1343608616960491521</td>\n      <td>1343576442722893825</td>\n      <td>1.609176e+12</td>\n      <td>2020-12-28 17:23:51</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>@richierichhhhh_ Absolutely</td>\n      <td>en</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[{'screen_name': 'richierichhhhh_', 'name': 'R...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1343608530998153222</td>\n      <td>1343320495127633920</td>\n      <td>1.609176e+12</td>\n      <td>2020-12-28 17:23:31</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>What should Tesla do with in-car gaming in an ...</td>\n      <td>en</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1343431408052662273</td>\n      <td>1343043963096326147</td>\n      <td>1.609134e+12</td>\n      <td>2020-12-28 05:39:42</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>@PPathole @WSJ Absolutely</td>\n      <td>en</td>\n      <td>[]</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[{'screen_name': 'PPathole', 'name': 'Pranay P...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 39 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# load twitter data from csv file\n",
    "file_to_load = os.path.join('Data', 'elon_musk_tweets_2011-2020.csv')\n",
    "twitter_archive = pd.read_csv(file_to_load)\n",
    "twitter_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         date                                               text  like_count  \\\n",
       "0  2020-12-28  Entertainment will be critical when cars drive...       55085   \n",
       "3  2020-12-28  What should Tesla do with in-car gaming in an ...       33830   \n",
       "6  2020-12-27  Try playing Polytopia in your Tesla! Great gam...      148037   \n",
       "34 2020-12-25  Change your horn sound to üêê, üêçüé∑, üí® or holiday ...      187368   \n",
       "35 2020-12-25  Merry Christmas &amp; happy holidays! üéÅ  https...      236833   \n",
       "\n",
       "    reply_count  retweet_count  \n",
       "0          2922           2611  \n",
       "3          6932            884  \n",
       "6          5355           4186  \n",
       "34         5373           6983  \n",
       "35         7496          13288  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-12-28</td>\n      <td>Entertainment will be critical when cars drive...</td>\n      <td>55085</td>\n      <td>2922</td>\n      <td>2611</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-12-28</td>\n      <td>What should Tesla do with in-car gaming in an ...</td>\n      <td>33830</td>\n      <td>6932</td>\n      <td>884</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2020-12-27</td>\n      <td>Try playing Polytopia in your Tesla! Great gam...</td>\n      <td>148037</td>\n      <td>5355</td>\n      <td>4186</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>2020-12-25</td>\n      <td>Change your horn sound to üêê, üêçüé∑, üí® or holiday ...</td>\n      <td>187368</td>\n      <td>5373</td>\n      <td>6983</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>2020-12-25</td>\n      <td>Merry Christmas &amp;amp; happy holidays! üéÅ  https...</td>\n      <td>236833</td>\n      <td>7496</td>\n      <td>13288</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# select and rename columns\n",
    "twitter_archive_clean = twitter_archive[['date', 'tweet', 'nlikes', 'nreplies', 'nretweets']]\\\n",
    "                            .loc[(twitter_archive['reply_to'] == '[]') & (twitter_archive['retweet'] == False)]\n",
    "twitter_archive_clean.columns=['date', 'text', 'like_count', 'reply_count', 'retweet_count']\n",
    "\n",
    "# convert date to datetime datatype\n",
    "twitter_archive_clean['date'] = pd.to_datetime(twitter_archive_clean['date']).dt.date.astype('datetime64')\n",
    "\n",
    "# drop last row with 1 tweet in 2010\n",
    "twitter_archive_clean.drop(twitter_archive_clean.tail(1).index,inplace=True)\n",
    "\n",
    "twitter_archive_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c62e0",
   "metadata": {},
   "source": [
    "## (1.3) Clean the twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 4619 entries, 0 to 11715\nData columns (total 5 columns):\n #   Column         Non-Null Count  Dtype         \n---  ------         --------------  -----         \n 0   date           4619 non-null   datetime64[ns]\n 1   text           4619 non-null   object        \n 2   like_count     4619 non-null   int64         \n 3   reply_count    4619 non-null   int64         \n 4   retweet_count  4619 non-null   int64         \ndtypes: datetime64[ns](1), int64(3), object(1)\nmemory usage: 216.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# concatenate 2 datasets to get tweets from 2011 to 2021\n",
    "twitter_df_merged = pd.concat([twitter_2021, twitter_archive_clean])\n",
    "twitter_df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "971be6ce",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            date                                               text  \\\n",
       "0     2021-07-14  Review of Model S Plaid by Dan Neil\\nhttps://t...   \n",
       "1     2021-07-14  Some light reading with lil X https://t.co/MHj...   \n",
       "2     2021-07-14  RT @Tesla: You can stream¬†Netflix &amp; YouTub...   \n",
       "3     2021-07-13  those who attack space\\nmaybe don‚Äôt realize th...   \n",
       "4     2021-07-13  Loki is pretty good. Basically, live-action @R...   \n",
       "...          ...                                                ...   \n",
       "11711 2011-12-04  Am reading a great biography of Ben Franklin b...   \n",
       "11712 2011-12-03                  That was a total non sequitur btw   \n",
       "11713 2011-12-03  Great Voltaire quote, arguably better than Twa...   \n",
       "11714 2011-12-01  I made the volume on the Model S  http://t.co/...   \n",
       "11715 2011-12-01  Went to Iceland on Sat to ride bumper cars on ...   \n",
       "\n",
       "       like_count  reply_count  retweet_count  \n",
       "0           35736         8979           3219  \n",
       "1          123524         6946           5048  \n",
       "2               0            0           2943  \n",
       "3          256947        32331          23730  \n",
       "4          138710         7435           9350  \n",
       "...           ...          ...            ...  \n",
       "11711          65           17              9  \n",
       "11712          53           31              6  \n",
       "11713          29            7             25  \n",
       "11714          78           31              9  \n",
       "11715         189           32             15  \n",
       "\n",
       "[4619 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-07-14</td>\n      <td>Review of Model S Plaid by Dan Neil\\nhttps://t...</td>\n      <td>35736</td>\n      <td>8979</td>\n      <td>3219</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-07-14</td>\n      <td>Some light reading with lil X https://t.co/MHj...</td>\n      <td>123524</td>\n      <td>6946</td>\n      <td>5048</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-07-14</td>\n      <td>RT @Tesla: You can stream¬†Netflix &amp;amp; YouTub...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2943</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-07-13</td>\n      <td>those who attack space\\nmaybe don‚Äôt realize th...</td>\n      <td>256947</td>\n      <td>32331</td>\n      <td>23730</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-07-13</td>\n      <td>Loki is pretty good. Basically, live-action @R...</td>\n      <td>138710</td>\n      <td>7435</td>\n      <td>9350</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11711</th>\n      <td>2011-12-04</td>\n      <td>Am reading a great biography of Ben Franklin b...</td>\n      <td>65</td>\n      <td>17</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>11712</th>\n      <td>2011-12-03</td>\n      <td>That was a total non sequitur btw</td>\n      <td>53</td>\n      <td>31</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>11713</th>\n      <td>2011-12-03</td>\n      <td>Great Voltaire quote, arguably better than Twa...</td>\n      <td>29</td>\n      <td>7</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>11714</th>\n      <td>2011-12-01</td>\n      <td>I made the volume on the Model S  http://t.co/...</td>\n      <td>78</td>\n      <td>31</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>11715</th>\n      <td>2011-12-01</td>\n      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n      <td>189</td>\n      <td>32</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n<p>4619 rows √ó 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Drop the NaNs\n",
    "twitter_df_merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b731df31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# group tweets that posted at the same day\n",
    "def f(x):\n",
    "     return pd.Series(dict(like_count = x['like_count'].sum(),\n",
    "                        reply_count = x['reply_count'].sum(),\n",
    "                        retweet_count = x['retweet_count'].sum(),\n",
    "                        text = \"{%s}\" % ', '.join(x['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d661c8a",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date  like_count  reply_count  retweet_count  \\\n",
       "0 2011-12-01         267           63             24   \n",
       "1 2011-12-03          82           38             31   \n",
       "2 2011-12-04          65           17              9   \n",
       "3 2011-12-21        1330           87            597   \n",
       "4 2011-12-22        1349          132            206   \n",
       "\n",
       "                                                text  \n",
       "0  {I made the volume on the Model S  http://t.co...  \n",
       "1  {That was a total non sequitur btw, Great Volt...  \n",
       "2  {Am reading a great biography of Ben Franklin ...  \n",
       "3  {Yum! Even better than deep fried butter:  htt...  \n",
       "4  {Model S options are out! Performance in red a...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-12-01</td>\n      <td>267</td>\n      <td>63</td>\n      <td>24</td>\n      <td>{I made the volume on the Model S  http://t.co...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-12-03</td>\n      <td>82</td>\n      <td>38</td>\n      <td>31</td>\n      <td>{That was a total non sequitur btw, Great Volt...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-12-04</td>\n      <td>65</td>\n      <td>17</td>\n      <td>9</td>\n      <td>{Am reading a great biography of Ben Franklin ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-12-21</td>\n      <td>1330</td>\n      <td>87</td>\n      <td>597</td>\n      <td>{Yum! Even better than deep fried butter:  htt...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-12-22</td>\n      <td>1349</td>\n      <td>132</td>\n      <td>206</td>\n      <td>{Model S options are out! Performance in red a...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "twitter_df_merged = twitter_df_merged.groupby('date').apply(f).reset_index()\n",
    "twitter_df_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "date             1719\n",
       "like_count       1719\n",
       "reply_count      1719\n",
       "retweet_count    1719\n",
       "text             1719\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "twitter_df_merged.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad7518",
   "metadata": {},
   "source": [
    "## (1.4) Preprocessing the Twitter data\n",
    "\n",
    "**Preprocess the data by making it all lowercase. Remove a reasonable set of stopwords from the dataset and tokenize. Then, report the 10 most common words and their count. We need to iterate this process, adding some stop words as we understand the structure of the data. Justify additional stop words we've added.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0fd768a",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ziza/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date  like_count  reply_count  retweet_count  \\\n",
       "0 2011-12-01         267           63             24   \n",
       "1 2011-12-03          82           38             31   \n",
       "2 2011-12-04          65           17              9   \n",
       "3 2011-12-21        1330           87            597   \n",
       "4 2011-12-22        1349          132            206   \n",
       "\n",
       "                                                text  \\\n",
       "0  {I made the volume on the Model S  http://t.co...   \n",
       "1  {That was a total non sequitur btw, Great Volt...   \n",
       "2  {Am reading a great biography of Ben Franklin ...   \n",
       "3  {Yum! Even better than deep fried butter:  htt...   \n",
       "4  {Model S options are out! Performance in red a...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  {i made the volume on the model s go to 11. no...   \n",
       "1  {that was a total non sequitur btw, great volt...   \n",
       "2  {am reading a great biography of ben franklin ...   \n",
       "3  {yum! even better than deep fried butter: yeah...   \n",
       "4  {model s options are out! performance in red a...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [made, volume, model, go, need, work, miniatur...  \n",
       "1  [total, non, sequitur, great, voltaire, quote,...  \n",
       "2  [reading, great, biography, ben, franklin, isa...  \n",
       "3  [yum, even, better, deep, fried, butter, yeah,...  \n",
       "4  [model, options, performance, red, black, deli...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n      <th>text</th>\n      <th>preprocessed_text</th>\n      <th>tokenized_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-12-01</td>\n      <td>267</td>\n      <td>63</td>\n      <td>24</td>\n      <td>{I made the volume on the Model S  http://t.co...</td>\n      <td>{i made the volume on the model s go to 11. no...</td>\n      <td>[made, volume, model, go, need, work, miniatur...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-12-03</td>\n      <td>82</td>\n      <td>38</td>\n      <td>31</td>\n      <td>{That was a total non sequitur btw, Great Volt...</td>\n      <td>{that was a total non sequitur btw, great volt...</td>\n      <td>[total, non, sequitur, great, voltaire, quote,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-12-04</td>\n      <td>65</td>\n      <td>17</td>\n      <td>9</td>\n      <td>{Am reading a great biography of Ben Franklin ...</td>\n      <td>{am reading a great biography of ben franklin ...</td>\n      <td>[reading, great, biography, ben, franklin, isa...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-12-21</td>\n      <td>1330</td>\n      <td>87</td>\n      <td>597</td>\n      <td>{Yum! Even better than deep fried butter:  htt...</td>\n      <td>{yum! even better than deep fried butter: yeah...</td>\n      <td>[yum, even, better, deep, fried, butter, yeah,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-12-22</td>\n      <td>1349</td>\n      <td>132</td>\n      <td>206</td>\n      <td>{Model S options are out! Performance in red a...</td>\n      <td>{model s options are out! performance in red a...</td>\n      <td>[model, options, performance, red, black, deli...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Data Pre-processing and make the tweets all lowercase and remove stopwords.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from datetime import datetime\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "twitter_df = twitter_df_merged.copy()\n",
    "\n",
    "# lower the tweets\n",
    "twitter_df['preprocessed_text'] = twitter_df['text'].str.lower()\n",
    "\n",
    "# remove apostrophe from words and url\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"('[a-z])\\s\", \"\", row) for row in twitter_df['preprocessed_text']]\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"(?:https:\\/\\/\\S+)\\s\", \"\", row) for row in twitter_df['preprocessed_text']]\n",
    "                                      \n",
    "# filter out rest URLs\n",
    "url_re = '(?:https?:\\/\\/)?(?:[^?\\/\\s]+[?\\/])(.*)'\n",
    "twitter_df['preprocessed_text'] = twitter_df['preprocessed_text'].apply(lambda row: ' '.join([word for word in row.split() if (not re.match(url_re, word))]))\n",
    "\n",
    "# tokenize the tweets\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z]\\w+\\'?\\w*')\n",
    "twitter_df['tokenized_text'] = twitter_df['preprocessed_text'].apply(lambda row: tokenizer.tokenize(row))\n",
    "\n",
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# apply stemming\n",
    "twitter_df['preprocessed_text'] = [porter.stem(row) for row in twitter_df['preprocessed_text']]   \n",
    "\n",
    "# filter out stop words\n",
    "en_stop_words = nltk.corpus.stopwords.words('english')\n",
    "additional_stop_words =['amp', 'rt', 'th','co', 're', 've', 'kim', 'daca', 'us', 'it', 'th', 'you', 'haha', 'st', 'et', 'so', 'iii', 'also', 've', 'la', 're', 'the', 'https', 'wow', 'actually', 'due', 'ft', 'pcr', 'via', 'am', 'gt', 'com', 'since', 'in', 'me', 'and', 'btw', 'yesterday', 'ii', 'inu', 'on', 'http', 'to', 'vs', 'rd', 'ur', 'of', 'bs', 'km', 'est', 'em', 'lz', 'kms', 'aft', 'nd',  'here‚Äôs', 're', 'mqxfakpzf' 'mph', 'ht', 'etc', 'dm', 'doo']\n",
    "en_stop_words.extend(additional_stop_words)\n",
    "\n",
    "twitter_df['tokenized_text'] = twitter_df['tokenized_text'].apply(lambda row: [word for word in row if (not word in en_stop_words)])\n",
    "\n",
    "df_tweets_clean = twitter_df.copy()\n",
    "df_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caba4f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date                                               text  \\\n",
       "0 2011-12-01  {I made the volume on the Model S  http://t.co...   \n",
       "1 2011-12-03  {That was a total non sequitur btw, Great Volt...   \n",
       "2 2011-12-04  {Am reading a great biography of Ben Franklin ...   \n",
       "3 2011-12-21  {Yum! Even better than deep fried butter:  htt...   \n",
       "4 2011-12-22  {Model S options are out! Performance in red a...   \n",
       "5 2011-12-24  {The Russians are having some challenges with ...   \n",
       "6 2011-12-26  {Walked around a neighborhood recently rebuilt...   \n",
       "7 2011-12-27  {If you ever wanted to know the *real* truth a...   \n",
       "8 2011-12-28                             {@TheOnion So true :)}   \n",
       "9 2011-12-29  {Am not saying that is *necessarily* good or b...   \n",
       "\n",
       "                                      tokenized_text  like_count  reply_count  \\\n",
       "0  [made, volume, model, go, need, work, miniatur...         267           63   \n",
       "1  [total, non, sequitur, great, voltaire, quote,...          82           38   \n",
       "2  [reading, great, biography, ben, franklin, isa...          65           17   \n",
       "3  [yum, even, better, deep, fried, butter, yeah,...        1330           87   \n",
       "4  [model, options, performance, red, black, deli...        1349          132   \n",
       "5  [russians, challenges, rockets, many, engineer...      117113         1370   \n",
       "6  [walked, around, neighborhood, recently, rebui...         558          102   \n",
       "7  [ever, wanted, know, real, truth, moon, landin...          39           13   \n",
       "8                                   [theonion, true]          12            7   \n",
       "9  [saying, necessarily, good, bad, reality, forc...         187           39   \n",
       "\n",
       "   retweet_count  \n",
       "0             24  \n",
       "1             31  \n",
       "2              9  \n",
       "3            597  \n",
       "4            206  \n",
       "5           8434  \n",
       "6            171  \n",
       "7             34  \n",
       "8              1  \n",
       "9             41  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>text</th>\n      <th>tokenized_text</th>\n      <th>like_count</th>\n      <th>reply_count</th>\n      <th>retweet_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-12-01</td>\n      <td>{I made the volume on the Model S  http://t.co...</td>\n      <td>[made, volume, model, go, need, work, miniatur...</td>\n      <td>267</td>\n      <td>63</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-12-03</td>\n      <td>{That was a total non sequitur btw, Great Volt...</td>\n      <td>[total, non, sequitur, great, voltaire, quote,...</td>\n      <td>82</td>\n      <td>38</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-12-04</td>\n      <td>{Am reading a great biography of Ben Franklin ...</td>\n      <td>[reading, great, biography, ben, franklin, isa...</td>\n      <td>65</td>\n      <td>17</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-12-21</td>\n      <td>{Yum! Even better than deep fried butter:  htt...</td>\n      <td>[yum, even, better, deep, fried, butter, yeah,...</td>\n      <td>1330</td>\n      <td>87</td>\n      <td>597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-12-22</td>\n      <td>{Model S options are out! Performance in red a...</td>\n      <td>[model, options, performance, red, black, deli...</td>\n      <td>1349</td>\n      <td>132</td>\n      <td>206</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2011-12-24</td>\n      <td>{The Russians are having some challenges with ...</td>\n      <td>[russians, challenges, rockets, many, engineer...</td>\n      <td>117113</td>\n      <td>1370</td>\n      <td>8434</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2011-12-26</td>\n      <td>{Walked around a neighborhood recently rebuilt...</td>\n      <td>[walked, around, neighborhood, recently, rebui...</td>\n      <td>558</td>\n      <td>102</td>\n      <td>171</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2011-12-27</td>\n      <td>{If you ever wanted to know the *real* truth a...</td>\n      <td>[ever, wanted, know, real, truth, moon, landin...</td>\n      <td>39</td>\n      <td>13</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2011-12-28</td>\n      <td>{@TheOnion So true :)}</td>\n      <td>[theonion, true]</td>\n      <td>12</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2011-12-29</td>\n      <td>{Am not saying that is *necessarily* good or b...</td>\n      <td>[saying, necessarily, good, bad, reality, forc...</td>\n      <td>187</td>\n      <td>39</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df_tweets_clean = df_tweets_clean[['date', 'text', 'tokenized_text', 'like_count', 'reply_count', 'retweet_count']]\n",
    "df_tweets_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6338deb5",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8411"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# the most common words and their count\n",
    "def get_most_freq_words(str, n=None):\n",
    "    vect = CountVectorizer().fit(str)\n",
    "    bag_of_words = vect.transform(str)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
    "    return freq[:n]\n",
    "  \n",
    "len(get_most_freq_words([ word for tweet in df_tweets_clean.tokenized_text for word in tweet]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "effaa3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.to_csv('data/tweets_data_2010_2020.csv', index=False)"
   ]
  },
  {
   "source": [
    "## (1.5) Upload dataset to SQL Database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import psycopg2\n",
    "from config import user, password, hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{hostname}/twitter_vs_stocks')\n",
    "\n",
    "# Use the Inspector to explore the database\n",
    "inspector = inspect(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.to_sql('tweets_text', engine, if_exists ='append',method='multi', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf788124",
   "metadata": {},
   "source": [
    "# (2 ) Stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c8153",
   "metadata": {},
   "source": [
    "## (2.1) Getting the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ee54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "725dce38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           date        open        high         low       close    adjclose  \\\n",
       "0    2011-01-03    5.368000    5.400000    5.180000    5.324000    5.324000   \n",
       "1    2011-01-04    5.332000    5.390000    5.204000    5.334000    5.334000   \n",
       "2    2011-01-05    5.296000    5.380000    5.238000    5.366000    5.366000   \n",
       "3    2011-01-06    5.366000    5.600000    5.362000    5.576000    5.576000   \n",
       "4    2011-01-07    5.600000    5.716000    5.580000    5.648000    5.648000   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "2647 2021-07-12  662.200012  687.239990  662.159973  685.700012  685.700012   \n",
       "2648 2021-07-13  686.320007  693.280029  666.299988  668.539978  668.539978   \n",
       "2649 2021-07-14  670.750000  678.609985  652.840027  653.380005  653.380005   \n",
       "2650 2021-07-15  658.390015  666.140015  637.880005  650.599976  650.599976   \n",
       "2651 2021-07-16  654.679993  656.700012  642.200012  644.219971  644.219971   \n",
       "\n",
       "        volume ticker  \n",
       "0      6415000   TSLA  \n",
       "1      5937000   TSLA  \n",
       "2      7233500   TSLA  \n",
       "3     10306000   TSLA  \n",
       "4     11239500   TSLA  \n",
       "...        ...    ...  \n",
       "2647  25927000   TSLA  \n",
       "2648  20847500   TSLA  \n",
       "2649  21641200   TSLA  \n",
       "2650  20209600   TSLA  \n",
       "2651  16339800   TSLA  \n",
       "\n",
       "[2652 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adjclose</th>\n      <th>volume</th>\n      <th>ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-03</td>\n      <td>5.368000</td>\n      <td>5.400000</td>\n      <td>5.180000</td>\n      <td>5.324000</td>\n      <td>5.324000</td>\n      <td>6415000</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-04</td>\n      <td>5.332000</td>\n      <td>5.390000</td>\n      <td>5.204000</td>\n      <td>5.334000</td>\n      <td>5.334000</td>\n      <td>5937000</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-05</td>\n      <td>5.296000</td>\n      <td>5.380000</td>\n      <td>5.238000</td>\n      <td>5.366000</td>\n      <td>5.366000</td>\n      <td>7233500</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-01-06</td>\n      <td>5.366000</td>\n      <td>5.600000</td>\n      <td>5.362000</td>\n      <td>5.576000</td>\n      <td>5.576000</td>\n      <td>10306000</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-01-07</td>\n      <td>5.600000</td>\n      <td>5.716000</td>\n      <td>5.580000</td>\n      <td>5.648000</td>\n      <td>5.648000</td>\n      <td>11239500</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2647</th>\n      <td>2021-07-12</td>\n      <td>662.200012</td>\n      <td>687.239990</td>\n      <td>662.159973</td>\n      <td>685.700012</td>\n      <td>685.700012</td>\n      <td>25927000</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>2648</th>\n      <td>2021-07-13</td>\n      <td>686.320007</td>\n      <td>693.280029</td>\n      <td>666.299988</td>\n      <td>668.539978</td>\n      <td>668.539978</td>\n      <td>20847500</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>2649</th>\n      <td>2021-07-14</td>\n      <td>670.750000</td>\n      <td>678.609985</td>\n      <td>652.840027</td>\n      <td>653.380005</td>\n      <td>653.380005</td>\n      <td>21641200</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>2650</th>\n      <td>2021-07-15</td>\n      <td>658.390015</td>\n      <td>666.140015</td>\n      <td>637.880005</td>\n      <td>650.599976</td>\n      <td>650.599976</td>\n      <td>20209600</td>\n      <td>TSLA</td>\n    </tr>\n    <tr>\n      <th>2651</th>\n      <td>2021-07-16</td>\n      <td>654.679993</td>\n      <td>656.700012</td>\n      <td>642.200012</td>\n      <td>644.219971</td>\n      <td>644.219971</td>\n      <td>16339800</td>\n      <td>TSLA</td>\n    </tr>\n  </tbody>\n</table>\n<p>2652 rows √ó 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# historical daily data from Yahoo finance\n",
    "tesla_df = get_data(\"tsla\", start_date = '2011-01-01', end_date = None, index_as_date = False, interval=\"1d\")\n",
    "tesla_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e57be6",
   "metadata": {},
   "source": [
    "## (2.2) Clean the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72eba53e",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date   open   high    low  close    volume\n",
       "0 2011-01-03  5.368  5.400  5.180  5.324   6415000\n",
       "1 2011-01-04  5.332  5.390  5.204  5.334   5937000\n",
       "2 2011-01-05  5.296  5.380  5.238  5.366   7233500\n",
       "3 2011-01-06  5.366  5.600  5.362  5.576  10306000\n",
       "4 2011-01-07  5.600  5.716  5.580  5.648  11239500"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-03</td>\n      <td>5.368</td>\n      <td>5.400</td>\n      <td>5.180</td>\n      <td>5.324</td>\n      <td>6415000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-04</td>\n      <td>5.332</td>\n      <td>5.390</td>\n      <td>5.204</td>\n      <td>5.334</td>\n      <td>5937000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-05</td>\n      <td>5.296</td>\n      <td>5.380</td>\n      <td>5.238</td>\n      <td>5.366</td>\n      <td>7233500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-01-06</td>\n      <td>5.366</td>\n      <td>5.600</td>\n      <td>5.362</td>\n      <td>5.576</td>\n      <td>10306000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-01-07</td>\n      <td>5.600</td>\n      <td>5.716</td>\n      <td>5.580</td>\n      <td>5.648</td>\n      <td>11239500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# Drop adjclose column\n",
    "tesla_df = tesla_df.drop(columns=[\"adjclose\", \"ticker\"])\n",
    "tesla_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fff742f3",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "date      datetime64[ns]\n",
       "open             float64\n",
       "high             float64\n",
       "low              float64\n",
       "close            float64\n",
       "volume             int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# Determine data types for each column\n",
    "tesla_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc19c0",
   "metadata": {},
   "source": [
    "## (2.3) Preprocessing the Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f772a94",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        date   open   high    low  close    volume  change\n",
       "0 2011-01-03  5.368  5.400  5.180  5.324   6415000     NaN\n",
       "1 2011-01-04  5.332  5.390  5.204  5.334   5937000   0.010\n",
       "2 2011-01-05  5.296  5.380  5.238  5.366   7233500   0.032\n",
       "3 2011-01-06  5.366  5.600  5.362  5.576  10306000   0.210\n",
       "4 2011-01-07  5.600  5.716  5.580  5.648  11239500   0.072\n",
       "5 2011-01-10  5.634  5.736  5.610  5.690   6713500   0.042\n",
       "6 2011-01-11  5.718  5.742  5.384  5.392   8551000  -0.298\n",
       "7 2011-01-12  5.402  5.480  5.304  5.392   4822000   0.000\n",
       "8 2011-01-13  5.392  5.394  5.232  5.244   3618000  -0.148\n",
       "9 2011-01-14  5.230  5.316  5.122  5.150   5960000  -0.094"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>change</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-03</td>\n      <td>5.368</td>\n      <td>5.400</td>\n      <td>5.180</td>\n      <td>5.324</td>\n      <td>6415000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-04</td>\n      <td>5.332</td>\n      <td>5.390</td>\n      <td>5.204</td>\n      <td>5.334</td>\n      <td>5937000</td>\n      <td>0.010</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-05</td>\n      <td>5.296</td>\n      <td>5.380</td>\n      <td>5.238</td>\n      <td>5.366</td>\n      <td>7233500</td>\n      <td>0.032</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-01-06</td>\n      <td>5.366</td>\n      <td>5.600</td>\n      <td>5.362</td>\n      <td>5.576</td>\n      <td>10306000</td>\n      <td>0.210</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-01-07</td>\n      <td>5.600</td>\n      <td>5.716</td>\n      <td>5.580</td>\n      <td>5.648</td>\n      <td>11239500</td>\n      <td>0.072</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2011-01-10</td>\n      <td>5.634</td>\n      <td>5.736</td>\n      <td>5.610</td>\n      <td>5.690</td>\n      <td>6713500</td>\n      <td>0.042</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2011-01-11</td>\n      <td>5.718</td>\n      <td>5.742</td>\n      <td>5.384</td>\n      <td>5.392</td>\n      <td>8551000</td>\n      <td>-0.298</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2011-01-12</td>\n      <td>5.402</td>\n      <td>5.480</td>\n      <td>5.304</td>\n      <td>5.392</td>\n      <td>4822000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2011-01-13</td>\n      <td>5.392</td>\n      <td>5.394</td>\n      <td>5.232</td>\n      <td>5.244</td>\n      <td>3618000</td>\n      <td>-0.148</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2011-01-14</td>\n      <td>5.230</td>\n      <td>5.316</td>\n      <td>5.122</td>\n      <td>5.150</td>\n      <td>5960000</td>\n      <td>-0.094</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Calculate change in stock price\n",
    "tesla_df['change'] = tesla_df['close'].diff()\n",
    "tesla_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d712d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.to_csv('data/tesla_stocks.csv', index=False)"
   ]
  },
  {
   "source": [
    "## (2.4) Upload dataset to SQL Database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.to_sql('stock', engine, if_exists ='append',method='multi', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('mlenv': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "801dd5eee37480936b14d219984276aecdbc0fffcaa1c38299e8fde776f1c6c6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}