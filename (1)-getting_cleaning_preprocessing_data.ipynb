{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29d489e",
   "metadata": {},
   "source": [
    "# (1) Twitter Data\n",
    "## (1.1) Getting twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5765ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from path import Path\n",
    "\n",
    "from twarc import Twarc2, expansions\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73f8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import bearer_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b804e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Twarc2(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42efd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'elonmusk'\n",
    "posts_dict = {\n",
    "    'date':[],\n",
    "    'text':[],\n",
    "    'like_count':[],\n",
    "    'quote_count':[],\n",
    "    'reply_count':[],\n",
    "    'retweet_count':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bde4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull posts from Twitter and create a dictionary\n",
    "user_timeline = client.timeline(user=user, exclude_replies=True, start_time=datetime.datetime(2017,1,20, 0, 0, 0) )\n",
    "for page in user_timeline:\n",
    "    result = expansions.flatten(page)\n",
    "    for tweet in result:\n",
    "        posts_dict['date'].append(tweet['created_at'])\n",
    "        posts_dict['text'].append(tweet['text'])\n",
    "        posts_dict['like_count'].append(tweet['public_metrics']['like_count'])\n",
    "        posts_dict['quote_count'].append(tweet['public_metrics']['quote_count'])\n",
    "        posts_dict['reply_count'].append(tweet['public_metrics']['reply_count'])\n",
    "        posts_dict['retweet_count'].append(tweet['public_metrics']['retweet_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159622c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dictionary of posts to dataframe\n",
    "twitter_df = pd.DataFrame.from_dict(posts_dict)\n",
    "twitter_df.head()\n",
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c62e0",
   "metadata": {},
   "source": [
    "## (1.2) Clean the twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "971be6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-14T21:30:25.000Z</td>\n",
       "      <td>Some light reading with lil X https://t.co/MHj...</td>\n",
       "      <td>32561</td>\n",
       "      <td>208</td>\n",
       "      <td>3052</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-14T02:42:29.000Z</td>\n",
       "      <td>RT @Tesla: You can stream¬†Netflix &amp;amp; YouTub...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-13T03:05:20.000Z</td>\n",
       "      <td>those who attack space\\nmaybe don‚Äôt realize th...</td>\n",
       "      <td>239487</td>\n",
       "      <td>12754</td>\n",
       "      <td>30247</td>\n",
       "      <td>22302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-13T02:37:57.000Z</td>\n",
       "      <td>Loki is pretty good. Basically, live-action @R...</td>\n",
       "      <td>131552</td>\n",
       "      <td>2791</td>\n",
       "      <td>7032</td>\n",
       "      <td>8884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-13T02:30:16.000Z</td>\n",
       "      <td>ü§Ø https://t.co/Z11qszTY4v</td>\n",
       "      <td>292920</td>\n",
       "      <td>1886</td>\n",
       "      <td>9360</td>\n",
       "      <td>21895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>2020-06-21T06:19:41.000Z</td>\n",
       "      <td>If heat death is the end of the universe, it r...</td>\n",
       "      <td>144421</td>\n",
       "      <td>896</td>\n",
       "      <td>3530</td>\n",
       "      <td>12620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>2020-06-21T05:18:44.000Z</td>\n",
       "      <td>RT @cleantechnica: Exclusive Pro Photos: Tesla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>2020-06-21T00:31:25.000Z</td>\n",
       "      <td>RT @Tesla: https://t.co/26o1bAP14v</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>2020-06-19T17:06:03.000Z</td>\n",
       "      <td>Juneteenth is henceforth considered a US holid...</td>\n",
       "      <td>402576</td>\n",
       "      <td>2590</td>\n",
       "      <td>5885</td>\n",
       "      <td>31266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>2020-06-18T01:41:17.000Z</td>\n",
       "      <td>RT @SpaceX: More than 100 spacecraft have been...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>849 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date  \\\n",
       "0    2021-07-14T21:30:25.000Z   \n",
       "1    2021-07-14T02:42:29.000Z   \n",
       "2    2021-07-13T03:05:20.000Z   \n",
       "3    2021-07-13T02:37:57.000Z   \n",
       "4    2021-07-13T02:30:16.000Z   \n",
       "..                        ...   \n",
       "844  2020-06-21T06:19:41.000Z   \n",
       "845  2020-06-21T05:18:44.000Z   \n",
       "846  2020-06-21T00:31:25.000Z   \n",
       "847  2020-06-19T17:06:03.000Z   \n",
       "848  2020-06-18T01:41:17.000Z   \n",
       "\n",
       "                                                  text  like_count  \\\n",
       "0    Some light reading with lil X https://t.co/MHj...       32561   \n",
       "1    RT @Tesla: You can stream¬†Netflix &amp; YouTub...           0   \n",
       "2    those who attack space\\nmaybe don‚Äôt realize th...      239487   \n",
       "3    Loki is pretty good. Basically, live-action @R...      131552   \n",
       "4                            ü§Ø https://t.co/Z11qszTY4v      292920   \n",
       "..                                                 ...         ...   \n",
       "844  If heat death is the end of the universe, it r...      144421   \n",
       "845  RT @cleantechnica: Exclusive Pro Photos: Tesla...           0   \n",
       "846                 RT @Tesla: https://t.co/26o1bAP14v           0   \n",
       "847  Juneteenth is henceforth considered a US holid...      402576   \n",
       "848  RT @SpaceX: More than 100 spacecraft have been...           0   \n",
       "\n",
       "     quote_count  reply_count  retweet_count  \n",
       "0            208         3052           1750  \n",
       "1              0            0           2624  \n",
       "2          12754        30247          22302  \n",
       "3           2791         7032           8884  \n",
       "4           1886         9360          21895  \n",
       "..           ...          ...            ...  \n",
       "844          896         3530          12620  \n",
       "845            0            0            529  \n",
       "846            0            0           2167  \n",
       "847         2590         5885          31266  \n",
       "848            0            0           1794  \n",
       "\n",
       "[849 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the NaNs\n",
    "twitter_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "863da221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             object\n",
       "text             object\n",
       "like_count        int64\n",
       "quote_count       int64\n",
       "reply_count       int64\n",
       "retweet_count     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine data types for each column\n",
    "twitter_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba95493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378beb62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>Some light reading with lil X https://t.co/MHj...</td>\n",
       "      <td>32561</td>\n",
       "      <td>208</td>\n",
       "      <td>3052</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>RT @Tesla: You can stream¬†Netflix &amp;amp; YouTub...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>those who attack space\\nmaybe don‚Äôt realize th...</td>\n",
       "      <td>239487</td>\n",
       "      <td>12754</td>\n",
       "      <td>30247</td>\n",
       "      <td>22302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>Loki is pretty good. Basically, live-action @R...</td>\n",
       "      <td>131552</td>\n",
       "      <td>2791</td>\n",
       "      <td>7032</td>\n",
       "      <td>8884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>ü§Ø https://t.co/Z11qszTY4v</td>\n",
       "      <td>292920</td>\n",
       "      <td>1886</td>\n",
       "      <td>9360</td>\n",
       "      <td>21895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                               text  like_count  \\\n",
       "0 2021-07-14  Some light reading with lil X https://t.co/MHj...       32561   \n",
       "1 2021-07-14  RT @Tesla: You can stream¬†Netflix &amp; YouTub...           0   \n",
       "2 2021-07-13  those who attack space\\nmaybe don‚Äôt realize th...      239487   \n",
       "3 2021-07-13  Loki is pretty good. Basically, live-action @R...      131552   \n",
       "4 2021-07-13                          ü§Ø https://t.co/Z11qszTY4v      292920   \n",
       "\n",
       "   quote_count  reply_count  retweet_count  \n",
       "0          208         3052           1750  \n",
       "1            0            0           2624  \n",
       "2        12754        30247          22302  \n",
       "3         2791         7032           8884  \n",
       "4         1886         9360          21895  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's convert the date.\n",
    "twitter_df['date'] = pd.to_datetime(twitter_df['date']).dt.date.astype('datetime64')\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b731df31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "\n",
    "def f(x):\n",
    "     return Series(dict(like_count = x['like_count'].sum(),\n",
    "                        quote_count = x['quote_count'].sum(),\n",
    "                        reply_count = x['reply_count'].sum(),\n",
    "                        retweet_count = x['retweet_count'].sum(),\n",
    "                        text = \"{%s}\" % ', '.join(x['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d661c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1794</td>\n",
       "      <td>{RT @SpaceX: More than 100 spacecraft have bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>402576</td>\n",
       "      <td>2590</td>\n",
       "      <td>5885</td>\n",
       "      <td>31266</td>\n",
       "      <td>{Juneteenth is henceforth considered a US holi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>735154</td>\n",
       "      <td>4879</td>\n",
       "      <td>17987</td>\n",
       "      <td>57393</td>\n",
       "      <td>{2019 seems so quaint &amp;amp; long ago https://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>133437</td>\n",
       "      <td>892</td>\n",
       "      <td>5246</td>\n",
       "      <td>5438</td>\n",
       "      <td>{Tentative date for Tesla Shareholder Meeting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>259114</td>\n",
       "      <td>1039</td>\n",
       "      <td>4758</td>\n",
       "      <td>10807</td>\n",
       "      <td>{RT @GerberKawasaki: First thoughts driving my...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  like_count  quote_count  reply_count  retweet_count  \\\n",
       "0 2020-06-18           0            0            0           1794   \n",
       "1 2020-06-19      402576         2590         5885          31266   \n",
       "2 2020-06-21      735154         4879        17987          57393   \n",
       "3 2020-06-22      133437          892         5246           5438   \n",
       "4 2020-06-25      259114         1039         4758          10807   \n",
       "\n",
       "                                                text  \n",
       "0  {RT @SpaceX: More than 100 spacecraft have bee...  \n",
       "1  {Juneteenth is henceforth considered a US holi...  \n",
       "2  {2019 seems so quaint &amp; long ago https://t...  \n",
       "3  {Tentative date for Tesla Shareholder Meeting ...  \n",
       "4  {RT @GerberKawasaki: First thoughts driving my...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = twitter_df.groupby('date').apply(f).reset_index()\n",
    "twitter_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad7518",
   "metadata": {},
   "source": [
    "## (1.3) Preprocessing the Twitter data\n",
    "\n",
    "**Preprocess the data by making it all lowercase. Remove a reasonable set of stopwords from the dataset and tokenize. Then, report the 10 most common words and their count. We need to iterate this process, adding some stop words as we understand the structure of the data. Justify additional stop words we've added.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1c50479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['needn', 'before', 'own', 'weren', 'what']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Pre-processing and make the tweets all lowercase and remove stopwords.\n",
    "from nltk.corpus import stopwords\n",
    "en_stop_words = set(stopwords.words('english'))\n",
    "list(en_stop_words)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0fd768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'needn', 'before', 'own', 'weren', 'what', \"didn't\", 'for', \"doesn't\", 'the', \"you'd\", 'having', 'herself', 'during', 'will', 'km', 'was', 'mightn', \"it's\", 'than', 'as', \"mustn't\", 'into', 'also', 'to', 'until', 'actually', 'them', 'kim', 'from', 'after', 'daca', 'yesterday', 'further', 'rt', 'do', 'with', 'due', 'themselves', 'your', 'some', 'its', 'an', 'iii', 'yours', 'his', 'should', \"couldn't\", '&amp;', 'of', 'haha', 'th', 'bs', 'they', 'we', 'above', 'are', 'est', 'btw', 'which', 'don', 'has', 'co', 'and', \"wouldn't\", 'hers', 'kms', 'my', 'any', 'gt', 'not', 'ft', 'only', 'whom', 'o', \"you'll\", 'just', 'but', \"won't\", 'aft', 'each', 'no', 'again', 'yourselves', 'can', \"you've\", 'him', 'about', 'be', 'up', \"haven't\", 'where', 'now', 'her', 'how', \"don't\", 'out', 'vs', 'is', 'ain', 'i', 'd', 'wasn', 'myself', 'doing', 'while', 'lz', 'being', 'haven', 'shan', 'been', 'this', 'these', 'doesn', 'isn', \"shouldn't\", 'et', 'since', 'our', 'couldn', 'same', 't', 'didn', 'st', 'those', 'so', 'pcr', 'via', 'too', \"aren't\", 'by', 'com', 'ourselves', 'won', 'few', 'wow', 'hasn', 'in', 'other', 'there', 'https', \"hadn't\", 'ur', 'inu', 'am', 'their', 'against', 'em', 'more', 'between', 'la', 'me', 'down', 'off', 'all', 'ours', 'here', 'both', 'very', 'if', \"wasn't\", 'because', 'aren', 'ma', 'http', \"hasn't\", \"she's\", \"that'll\", \"weren't\", 'himself', 'over', 've', 'mustn', 'below', 'under', 'nd', 'he', 'once', 'such', 'you', 'a', 'us', \"you're\", 'nor', 'most', 'shouldn', 'at', 'here‚Äôs', 'does', 'have', 'm', 'll', 'did', 'why', 'y', 'on', 'rd', 'were', 'when', \"isn't\", 'wouldn', 'who', 'hadn', 're', 'that', 'through', 'yourself', \"shan't\", 'had', 'theirs', \"should've\", 'it', 's', 'itself', 'then', 'or', \"needn't\", 'ii', \"mightn't\", 'she'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zkirsan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1794</td>\n",
       "      <td>{RT @SpaceX: More than 100 spacecraft have bee...</td>\n",
       "      <td>{rt @spacex: 100 spacecraft signed fly falcon ...</td>\n",
       "      <td>[rt, spacex, spacecraft, signed, fly, falcon, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>402576</td>\n",
       "      <td>2590</td>\n",
       "      <td>5885</td>\n",
       "      <td>31266</td>\n",
       "      <td>{Juneteenth is henceforth considered a US holi...</td>\n",
       "      <td>{juneteenth henceforth considered holiday tesl...</td>\n",
       "      <td>[juneteenth, henceforth, considered, holiday, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>735154</td>\n",
       "      <td>4879</td>\n",
       "      <td>17987</td>\n",
       "      <td>57393</td>\n",
       "      <td>{2019 seems so quaint &amp;amp; long ago https://t...</td>\n",
       "      <td>{2019 seems quaint long ago purpose, tesla bio...</td>\n",
       "      <td>[seems, quaint, long, ago, purpose, tesla, bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>133437</td>\n",
       "      <td>892</td>\n",
       "      <td>5246</td>\n",
       "      <td>5438</td>\n",
       "      <td>{Tentative date for Tesla Shareholder Meeting ...</td>\n",
       "      <td>{tentative date tesla shareholder meeting batt...</td>\n",
       "      <td>[tentative, date, tesla, shareholder, meeting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>259114</td>\n",
       "      <td>1039</td>\n",
       "      <td>4758</td>\n",
       "      <td>10807</td>\n",
       "      <td>{RT @GerberKawasaki: First thoughts driving my...</td>\n",
       "      <td>{rt @gerberkawasaki: first thoughts driving ne...</td>\n",
       "      <td>[rt, gerberkawasaki, first, thoughts, driving,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  like_count  quote_count  reply_count  retweet_count  \\\n",
       "0 2020-06-18           0            0            0           1794   \n",
       "1 2020-06-19      402576         2590         5885          31266   \n",
       "2 2020-06-21      735154         4879        17987          57393   \n",
       "3 2020-06-22      133437          892         5246           5438   \n",
       "4 2020-06-25      259114         1039         4758          10807   \n",
       "\n",
       "                                                text  \\\n",
       "0  {RT @SpaceX: More than 100 spacecraft have bee...   \n",
       "1  {Juneteenth is henceforth considered a US holi...   \n",
       "2  {2019 seems so quaint &amp; long ago https://t...   \n",
       "3  {Tentative date for Tesla Shareholder Meeting ...   \n",
       "4  {RT @GerberKawasaki: First thoughts driving my...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  {rt @spacex: 100 spacecraft signed fly falcon ...   \n",
       "1  {juneteenth henceforth considered holiday tesl...   \n",
       "2  {2019 seems quaint long ago purpose, tesla bio...   \n",
       "3  {tentative date tesla shareholder meeting batt...   \n",
       "4  {rt @gerberkawasaki: first thoughts driving ne...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [rt, spacex, spacecraft, signed, fly, falcon, ...  \n",
       "1  [juneteenth, henceforth, considered, holiday, ...  \n",
       "2  [seems, quaint, long, ago, purpose, tesla, bio...  \n",
       "3  [tentative, date, tesla, shareholder, meeting,...  \n",
       "4  [rt, gerberkawasaki, first, thoughts, driving,...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from datetime import datetime\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "date_col='date'\n",
    "tweet_col='text'\n",
    "like_count= 'like_count'\n",
    "quote_count= 'quote_count'\n",
    "reply_count= 'reply_count'\n",
    "retweet_count= 'retweet_count'\n",
    "\n",
    "\n",
    "# lower the tweets\n",
    "twitter_df['preprocessed_' + tweet_col] = twitter_df[tweet_col].str.lower()\n",
    "\n",
    "# remove apostrophe from words\n",
    "twitter_df.preprocessed_text = [re.sub(\"(‚Äò[a-z])\\s\", \"\", row) for row in twitter_df.preprocessed_text] \n",
    "                                       \n",
    "# filter out stop words and URLs\n",
    "en_stop_words = set(stopwords.words('english'))\n",
    "extended_stop_words = en_stop_words | \\\n",
    "                    {\n",
    "                        '&amp;', 'rt',                            \n",
    "                          'th','co', 're', 've', 'kim', 'daca', 'us', 'it', 'th', 'you', 'haha', 'st', 'et', 'so', 'iii',\n",
    "                        'also', 've', 'la', 're', 'the', 'https', 'wow', 'actually', 'due', 'ft', 'pcr', 'via', 'am', 'gt',\n",
    "                        'com', 'since', 'in', 'me', 'and', 'btw', 'yesterday', 'ii', 'inu', 'on', 'http', 'to', 'vs', 'rd', \n",
    "                        'ur', 'of', 'bs', 'km', 'est', 'em', 'lz', 'kms', 'aft', 'nd',  'here‚Äôs'\n",
    "                    }\n",
    "print(extended_stop_words)\n",
    "\n",
    "url_re = '(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'        \n",
    "\n",
    "twitter_df['preprocessed_' + tweet_col] = twitter_df['preprocessed_' + tweet_col].apply(lambda row: ' '.join([word for word in row.split() if (not word in extended_stop_words) and (not re.match(url_re, word))]))\n",
    "\n",
    "# tokenize the tweets\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z]\\w+\\'?\\w*')\n",
    "twitter_df['tokenized_' + tweet_col] = twitter_df['preprocessed_' + tweet_col].apply(lambda row: tokenizer.tokenize(row))\n",
    "\n",
    "df_tweets_clean = twitter_df\n",
    "df_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caba4f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>{RT @SpaceX: More than 100 spacecraft have bee...</td>\n",
       "      <td>{rt @spacex: 100 spacecraft signed fly falcon ...</td>\n",
       "      <td>[rt, spacex, spacecraft, signed, fly, falcon, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>{Juneteenth is henceforth considered a US holi...</td>\n",
       "      <td>{juneteenth henceforth considered holiday tesl...</td>\n",
       "      <td>[juneteenth, henceforth, considered, holiday, ...</td>\n",
       "      <td>402576</td>\n",
       "      <td>2590</td>\n",
       "      <td>5885</td>\n",
       "      <td>31266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>{2019 seems so quaint &amp;amp; long ago https://t...</td>\n",
       "      <td>{2019 seems quaint long ago purpose, tesla bio...</td>\n",
       "      <td>[seems, quaint, long, ago, purpose, tesla, bio...</td>\n",
       "      <td>735154</td>\n",
       "      <td>4879</td>\n",
       "      <td>17987</td>\n",
       "      <td>57393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>{Tentative date for Tesla Shareholder Meeting ...</td>\n",
       "      <td>{tentative date tesla shareholder meeting batt...</td>\n",
       "      <td>[tentative, date, tesla, shareholder, meeting,...</td>\n",
       "      <td>133437</td>\n",
       "      <td>892</td>\n",
       "      <td>5246</td>\n",
       "      <td>5438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>{RT @GerberKawasaki: First thoughts driving my...</td>\n",
       "      <td>{rt @gerberkawasaki: first thoughts driving ne...</td>\n",
       "      <td>[rt, gerberkawasaki, first, thoughts, driving,...</td>\n",
       "      <td>259114</td>\n",
       "      <td>1039</td>\n",
       "      <td>4758</td>\n",
       "      <td>10807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>{.@JeffBezos is a copy üêà haha https://t.co/plR...</td>\n",
       "      <td>{.@jeffbezos copy üêà controls memes, controls u...</td>\n",
       "      <td>[jeffbezos, copy, controls, memes, controls, u...</td>\n",
       "      <td>2246288</td>\n",
       "      <td>24439</td>\n",
       "      <td>32931</td>\n",
       "      <td>300115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>{Btw, Tesla actually receives *least* subsidie...</td>\n",
       "      <td>{btw, tesla receives *least* subsidies automak...</td>\n",
       "      <td>[btw, tesla, receives, least, subsidies, autom...</td>\n",
       "      <td>549422</td>\n",
       "      <td>5325</td>\n",
       "      <td>10659</td>\n",
       "      <td>55453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>{Your GPS just got slightly better https://t.c...</td>\n",
       "      <td>{your gps got slightly better @spacex: falcon ...</td>\n",
       "      <td>[your, gps, got, slightly, better, spacex, fal...</td>\n",
       "      <td>156694</td>\n",
       "      <td>688</td>\n",
       "      <td>2610</td>\n",
       "      <td>21577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>{Tesla Impact Report (repost). We do everythin...</td>\n",
       "      <td>{tesla impact report (repost). everything huma...</td>\n",
       "      <td>[tesla, impact, report, repost, everything, hu...</td>\n",
       "      <td>26862</td>\n",
       "      <td>208</td>\n",
       "      <td>1657</td>\n",
       "      <td>2530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>{Thanks Tesla owners &amp;amp; investors! Love you...</td>\n",
       "      <td>{thanks tesla owners investors! love you!! wor...</td>\n",
       "      <td>[thanks, tesla, owners, investors, love, you, ...</td>\n",
       "      <td>600565</td>\n",
       "      <td>11573</td>\n",
       "      <td>31287</td>\n",
       "      <td>39509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                               text  \\\n",
       "0 2020-06-18  {RT @SpaceX: More than 100 spacecraft have bee...   \n",
       "1 2020-06-19  {Juneteenth is henceforth considered a US holi...   \n",
       "2 2020-06-21  {2019 seems so quaint &amp; long ago https://t...   \n",
       "3 2020-06-22  {Tentative date for Tesla Shareholder Meeting ...   \n",
       "4 2020-06-25  {RT @GerberKawasaki: First thoughts driving my...   \n",
       "5 2020-06-26  {.@JeffBezos is a copy üêà haha https://t.co/plR...   \n",
       "6 2020-06-28  {Btw, Tesla actually receives *least* subsidie...   \n",
       "7 2020-06-30  {Your GPS just got slightly better https://t.c...   \n",
       "8 2020-07-01  {Tesla Impact Report (repost). We do everythin...   \n",
       "9 2020-07-02  {Thanks Tesla owners &amp; investors! Love you...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  {rt @spacex: 100 spacecraft signed fly falcon ...   \n",
       "1  {juneteenth henceforth considered holiday tesl...   \n",
       "2  {2019 seems quaint long ago purpose, tesla bio...   \n",
       "3  {tentative date tesla shareholder meeting batt...   \n",
       "4  {rt @gerberkawasaki: first thoughts driving ne...   \n",
       "5  {.@jeffbezos copy üêà controls memes, controls u...   \n",
       "6  {btw, tesla receives *least* subsidies automak...   \n",
       "7  {your gps got slightly better @spacex: falcon ...   \n",
       "8  {tesla impact report (repost). everything huma...   \n",
       "9  {thanks tesla owners investors! love you!! wor...   \n",
       "\n",
       "                                      tokenized_text  like_count  quote_count  \\\n",
       "0  [rt, spacex, spacecraft, signed, fly, falcon, ...           0            0   \n",
       "1  [juneteenth, henceforth, considered, holiday, ...      402576         2590   \n",
       "2  [seems, quaint, long, ago, purpose, tesla, bio...      735154         4879   \n",
       "3  [tentative, date, tesla, shareholder, meeting,...      133437          892   \n",
       "4  [rt, gerberkawasaki, first, thoughts, driving,...      259114         1039   \n",
       "5  [jeffbezos, copy, controls, memes, controls, u...     2246288        24439   \n",
       "6  [btw, tesla, receives, least, subsidies, autom...      549422         5325   \n",
       "7  [your, gps, got, slightly, better, spacex, fal...      156694          688   \n",
       "8  [tesla, impact, report, repost, everything, hu...       26862          208   \n",
       "9  [thanks, tesla, owners, investors, love, you, ...      600565        11573   \n",
       "\n",
       "   reply_count  retweet_count  \n",
       "0            0           1794  \n",
       "1         5885          31266  \n",
       "2        17987          57393  \n",
       "3         5246           5438  \n",
       "4         4758          10807  \n",
       "5        32931         300115  \n",
       "6        10659          55453  \n",
       "7         2610          21577  \n",
       "8         1657           2530  \n",
       "9        31287          39509  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_clean = df_tweets_clean[['date', 'text', 'preprocessed_text', 'tokenized_text', 'like_count', 'quote_count', 'reply_count', 'retweet_count']]\n",
    "df_tweets_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6338deb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spacex', 176),\n",
       " ('tesla', 116),\n",
       " ('rt', 67),\n",
       " ('launch', 57),\n",
       " ('dragon', 56),\n",
       " ('falcon', 54),\n",
       " ('first', 44),\n",
       " ('crew', 37),\n",
       " ('nasa', 36),\n",
       " ('space_station', 30)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the most common words and their count\n",
    "def get_most_freq_words(str, n=None):\n",
    "    vect = CountVectorizer().fit(str)\n",
    "    bag_of_words = vect.transform(str)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
    "    return freq[:n]\n",
    "  \n",
    "get_most_freq_words([ word for tweet in df_tweets_clean.tokenized_text for word in tweet],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effaa3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.to_csv('data/tweets_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf788124",
   "metadata": {},
   "source": [
    "# (2 ) Stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c8153",
   "metadata": {},
   "source": [
    "## (2.1) Getting the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from yahoo_fin.stock_info import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725dce38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# historical daily data from Yahoo finance\n",
    "tesla_df = get_data(\"tsla\", start_date = None, end_date = None, index_as_date = False, interval=\"1d\")\n",
    "tesla_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e57be6",
   "metadata": {},
   "source": [
    "## (2.2) Clean the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eba53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop adjclose column\n",
    "tesla_df = tesla_df.drop(columns=[\"adjclose\", \"ticker\"])\n",
    "tesla_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff742f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine data types for each column\n",
    "tesla_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc19c0",
   "metadata": {},
   "source": [
    "## (2.3) Preprocessing the Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f772a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate change in stock price\n",
    "tesla_df['change'] = tesla_df['close'].diff()\n",
    "tesla_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d712d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.to_csv('data/tesla_stocks', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dcd05f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
